{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripcion del notebook\n",
    "\n",
    "El objetivo de este notebook es generar un dataframe que contenga información de todos los productos en todos los días. \n",
    "\n",
    "El dataframe que se usa como fuente es el que se genera en el notebook `C2`\n",
    "\n",
    "__IMPORTANTE:__ Debido a que el proceso es muy lento, y el tiempo es reducido, el dataframe de este notebook no se ha usado en los modelos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el dataframe que contiene la curva de stock para cada dia y producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"train_grouped2.csv\",index_col=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengo las ids unicas de los productos que están en todo el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_ids = df_1.index.get_level_values(1).unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_final = df_1.index.get_level_values(0).unique().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un dataframe de la siguiente estructura.\n",
    "\n",
    "* Las filas representan los días del dataframe (64 días). \n",
    "* Las columnas representan los productos del dataframe (8722 productos).\n",
    "\n",
    "Cada celda puede tener 2 valores, `True` o `False`. \n",
    "* Si hay un `True` significa que para ese producto en ese dia, existe un valor en el daframe\n",
    "* Si hay un `False`, por el contrario, significa que ese producto en ese día no tiene valor en el dataframe\n",
    "\n",
    "Para obtener los valores, recorro el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_products = lista_ids\n",
    "\n",
    "incompletos = {}\n",
    "for j in tqdm(ids_products):\n",
    "    existe = []\n",
    "    for i in range(0,dia_final+1):\n",
    "        existe.append(df_1.index.isin([(i, j)]).any())\n",
    "    incompletos[j] = existe\n",
    "\n",
    "curvas = pd.DataFrame(incompletos)\n",
    "# pd.DataFrame(curvas).to_csv(\"info_curva_informada.csv\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono los registros que necesita que se les cree algún registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_con_huecos = []\n",
    "for i in tqdm(curvas.columns):\n",
    "    x = curvas[i] == False\n",
    "    if (x.unique().shape[0] == 2) or ((x.unique().shape[0] == 1) & (x.unique()[0] == True)):\n",
    "        dia_con_huecos.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `vacios_completos` están las ids de los productos que necesita algún registro para tener la curva de stocks completa (de 0 a 63)\n",
    "\n",
    "Creo los registros que faltan con  `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_producto in tqdm(dia_con_huecos):\n",
    "    producto_curvas = curvas[id_producto]  \n",
    "    for index,value in enumerate(producto_curvas.to_list()):\n",
    "        # Selecciono solo los False\n",
    "        if not value:\n",
    "            df_1.loc[(index,id_producto),:] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, reconstruimos la curva, rellenando los datos a nulo. \n",
    "\n",
    "Este proceso sigue esta lógica:\n",
    "\n",
    "- Los campos `price`,`block_id`,`family_id`,`subfamily_id` contienen información que no cambia en el tiempo. Se rellenan los nulos con el único valor que existe para ese producto en toda la linea temporal con este esquema:\n",
    "```py\n",
    "subconjunto.loc[:,campo].fillna(subconjunto[campo].dropna().unique()[0],inplace=True)\n",
    "```\n",
    "\n",
    "- Los campos `color_id`,`size_id`,`stock` se rellenan a partir de la información que exista de ellos. Si no existen en el día 0, se inicializan con valor 0.0. Se sigue la estrategia de reemplazo `foward fill`. Así, si un producto aparece por primera vez en el día 7, por ejemplo, se asume que no existen en la tienda hasta ese día, por lo que decir que su stock es 0 es correcto. A partir de ahí, si un producto no realiza una venta un día, se puede asumir que tiene el mismo stock que el día anterior.   \n",
    "\n",
    "- El campo `sales` se rellena siempre a 0.0 si no existe en un día (si es NaN).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_producto in tqdm(dia_con_huecos):\n",
    "    # Selecciono todos los días de un producto. \n",
    "    prueba_train_expandido = df_1.loc[pd.IndexSlice[:,id_producto], :]\n",
    "\n",
    "    prueba_train_expandido.loc[:,'price'].fillna(prueba_train_expandido['price'].dropna().unique()[0],inplace=True)\n",
    "    prueba_train_expandido.loc[:,'block_id'].fillna(prueba_train_expandido['block_id'].dropna().unique()[0],inplace=True)\n",
    "    prueba_train_expandido.loc[:,'family_id'].fillna(prueba_train_expandido['family_id'].dropna().unique()[0],inplace=True)\n",
    "    prueba_train_expandido.loc[:,'subfamily_id'].fillna(prueba_train_expandido['subfamily_id'].dropna().unique()[0],inplace=True)\n",
    "\n",
    "    if prueba_train_expandido.loc[0,'color_id'].any() == False:\n",
    "        prueba_train_expandido.loc[0,'color_id'] = 0.0\n",
    "\n",
    "    if prueba_train_expandido.loc[0,'size_id'].any() == False:\n",
    "        prueba_train_expandido.loc[0,'size_id']= 0.0\n",
    "\n",
    "    if prueba_train_expandido.loc[0,'stock'].any() == False:\n",
    "        prueba_train_expandido.loc[0,'stock'] = 0.0\n",
    "\n",
    "\n",
    "    prueba_train_expandido['color_id'].fillna(method='ffill',inplace=True)\n",
    "    prueba_train_expandido['size_id'].fillna(method='ffill',inplace=True)\n",
    "    prueba_train_expandido['sales'].fillna(0.0,inplace=True)\n",
    "    prueba_train_expandido['stock'].fillna(method='ffill',inplace=True)\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, ordenamos el dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el dataframe en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(\"full_csv_stocks.csv\",header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
