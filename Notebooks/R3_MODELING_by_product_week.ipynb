{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from eli5 import show_weights, show_prediction\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Masking\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/week2/final_train_pw.csv')\n",
    "test = pd.read_csv('../data/week2/final_test_pw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>position</th>\n",
       "      <th>category_id</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310130</td>\n",
       "      <td>1726</td>\n",
       "      <td>1383</td>\n",
       "      <td>34.811328</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>8379</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1178388</td>\n",
       "      <td>592</td>\n",
       "      <td>60</td>\n",
       "      <td>2.160247</td>\n",
       "      <td>0.048806</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>545</td>\n",
       "      <td>1020</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>15012</td>\n",
       "      <td>13</td>\n",
       "      <td>283</td>\n",
       "      <td>169</td>\n",
       "      <td>13</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1561460</td>\n",
       "      <td>1625</td>\n",
       "      <td>2373</td>\n",
       "      <td>55.438769</td>\n",
       "      <td>0.125812</td>\n",
       "      <td>0.023725</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>664</td>\n",
       "      <td>2221</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11650</td>\n",
       "      <td>13</td>\n",
       "      <td>1573</td>\n",
       "      <td>519</td>\n",
       "      <td>16</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1874414</td>\n",
       "      <td>1135</td>\n",
       "      <td>1686</td>\n",
       "      <td>20.463906</td>\n",
       "      <td>0.110088</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>610</td>\n",
       "      <td>1317</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7360</td>\n",
       "      <td>13</td>\n",
       "      <td>366</td>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2436420</td>\n",
       "      <td>779</td>\n",
       "      <td>245</td>\n",
       "      <td>23.377339</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>206</td>\n",
       "      <td>414</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11650</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  block_id  stock  std_stock  family_id  subfamily_id  size_id  \\\n",
       "0      310130      1726   1383  34.811328   0.007360      0.000577        7   \n",
       "1     1178388       592     60   2.160247   0.048806      0.012188        4   \n",
       "2     1561460      1625   2373  55.438769   0.125812      0.023725        5   \n",
       "3     1874414      1135   1686  20.463906   0.110088      0.015927        6   \n",
       "4     2436420       779    245  23.377339   0.026000      0.004422        5   \n",
       "\n",
       "   color_id  position  category_id  ...   N2    N3  N5  N6     N7  N8    N9  \\\n",
       "0         1       3.0            3  ...   17    54  13  11   8379  13    13   \n",
       "1         1      19.0            1  ...  545  1020  13  13  15012  13   283   \n",
       "2         1      38.0            3  ...  664  2221  13  13  11650  13  1573   \n",
       "3         1      12.0            6  ...  610  1317  13  13   7360  13   366   \n",
       "4         1       NaN            0  ...  206   414  13  13  11650  13    36   \n",
       "\n",
       "   N10  N12  N13  \n",
       "0   11   18   17  \n",
       "1  169   13  543  \n",
       "2  519   16  664  \n",
       "3   93   13  584  \n",
       "4   22   22  206  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>position</th>\n",
       "      <th>category_id</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151926</td>\n",
       "      <td>1969</td>\n",
       "      <td>2005</td>\n",
       "      <td>27.864312</td>\n",
       "      <td>0.125812</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1180</td>\n",
       "      <td>3020</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11650</td>\n",
       "      <td>4</td>\n",
       "      <td>1689</td>\n",
       "      <td>580</td>\n",
       "      <td>4</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213413</td>\n",
       "      <td>1648</td>\n",
       "      <td>4859</td>\n",
       "      <td>36.709667</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>219</td>\n",
       "      <td>207</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8379</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310130</td>\n",
       "      <td>1726</td>\n",
       "      <td>2745</td>\n",
       "      <td>44.600570</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7360</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>455200</td>\n",
       "      <td>1400</td>\n",
       "      <td>337</td>\n",
       "      <td>5.841971</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>486</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9242</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>571044</td>\n",
       "      <td>1098</td>\n",
       "      <td>1591</td>\n",
       "      <td>42.096330</td>\n",
       "      <td>0.099054</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>276</td>\n",
       "      <td>1389</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2433</td>\n",
       "      <td>10</td>\n",
       "      <td>556</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  block_id  stock  std_stock  family_id  subfamily_id  size_id  \\\n",
       "0      151926      1969   2005  27.864312   0.125812      0.032623        5   \n",
       "1      213413      1648   4859  36.709667   0.027100      0.002211        7   \n",
       "2      310130      1726   2745  44.600570   0.007360      0.000577        6   \n",
       "3      455200      1400    337   5.841971   0.049799      0.008652        3   \n",
       "4      571044      1098   1591  42.096330   0.099054      0.021951        4   \n",
       "\n",
       "   color_id  position  category_id  ...    N2    N3  N5  N6     N7  N8    N9  \\\n",
       "0         1      17.0            2  ...  1180  3020   4   4  11650   4  1689   \n",
       "1         1      59.0            2  ...   219   207  12  12   8379  12    53   \n",
       "2         1      48.0            1  ...     9    54  13   2   7360  13    13   \n",
       "3         1      44.0            2  ...   250   486   6   6   9242   6   110   \n",
       "4         2     180.0            2  ...   276  1389  10  10   2433  10   556   \n",
       "\n",
       "   N10  N12   N13  \n",
       "0  580    4  1180  \n",
       "1   40   12   133  \n",
       "2    2    4     9  \n",
       "3   83    7   182  \n",
       "4  108   10   223  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['sales', 'date_number', 'product_id', 'block_id']\n",
    "\n",
    "X_train = train.loc[:,[c for c in train.columns if c not in drop_cols]]\n",
    "y_train = train[['sales']]\n",
    "X_test = test.loc[:,[c for c in train.columns if c not in drop_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarización de las variables para modelos lineales y redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ss = ['stock', 'std_stock', 'position', 'stock_lag1',\n",
    "       'stock_lead1', 'std_stock_shift1', 'mean_stock_shift1',\n",
    "       'min_stock_shift1', 'max_stock_shift1', 'median_stock_shift1',\n",
    "       'stock_lag2', 'stock_lead2', 'std_stock_shift2', 'min_stock_shift2',\n",
    "       'max_stock_shift2', 'median_stock_shift2', 'mean_stock_shift2',\n",
    "       'pos_lag1', 'pos_lead1', 'std_pos_shift1', 'mean_pos_shift1',\n",
    "       'min_pos_shift1', 'max_pos_shift1', 'median_pos_shift1', 'pos_lag2',\n",
    "       'pos_lead2', 'std_pos_shift2', 'min_pos_shift2', 'max_pos_shift2',\n",
    "       'median_pos_shift2', 'mean_pos_shift2', 'diff_stock_lead1',\n",
    "       'diff_stock_lead2', 'diff_stock_lag1', 'diff_stock_lag2',\n",
    "       'diff_pos_lead1', 'diff_pos_lead2', 'diff_pos_lag1', 'diff_pos_lag2',\n",
    "       'std_stock_shift3', 'mean_stock_shift3', 'min_stock_shift3',\n",
    "       'max_stock_shift3', 'median_stock_shift3', 'std_pos_shift3',\n",
    "       'mean_pos_shift3', 'min_pos_shift3', 'max_pos_shift3',\n",
    "       'median_pos_shift3', 'ratio_position',\n",
    "       'N1', 'N2', 'N3', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'N12', 'N13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train[cols_ss])\n",
    "X_train[cols_ss] = ss.transform(X_train[cols_ss])\n",
    "X_test[cols_ss] = ss.transform(X_test[cols_ss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>position</th>\n",
       "      <th>category_id</th>\n",
       "      <th>price</th>\n",
       "      <th>stock_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.282039</td>\n",
       "      <td>0.166092</td>\n",
       "      <td>0.125812</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.607923</td>\n",
       "      <td>2</td>\n",
       "      <td>25.95</td>\n",
       "      <td>-0.127604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.593296</td>\n",
       "      <td>3.400102</td>\n",
       "      <td>-2.880808</td>\n",
       "      <td>-1.474544</td>\n",
       "      <td>0.667705</td>\n",
       "      <td>-2.880808</td>\n",
       "      <td>4.454870</td>\n",
       "      <td>3.846410</td>\n",
       "      <td>-1.248607</td>\n",
       "      <td>3.361188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.457501</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.257034</td>\n",
       "      <td>2</td>\n",
       "      <td>19.95</td>\n",
       "      <td>0.208348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185230</td>\n",
       "      <td>-0.726099</td>\n",
       "      <td>0.236814</td>\n",
       "      <td>0.669195</td>\n",
       "      <td>-0.019229</td>\n",
       "      <td>0.236814</td>\n",
       "      <td>-0.559229</td>\n",
       "      <td>-0.397491</td>\n",
       "      <td>-0.116643</td>\n",
       "      <td>-0.355666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.213757</td>\n",
       "      <td>0.717466</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.348934</td>\n",
       "      <td>1</td>\n",
       "      <td>12.95</td>\n",
       "      <td>-0.197198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.792400</td>\n",
       "      <td>-0.950525</td>\n",
       "      <td>0.626516</td>\n",
       "      <td>-2.010479</td>\n",
       "      <td>-0.233227</td>\n",
       "      <td>0.626516</td>\n",
       "      <td>-0.681823</td>\n",
       "      <td>-0.696136</td>\n",
       "      <td>-1.248607</td>\n",
       "      <td>-0.795867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.435951</td>\n",
       "      <td>-0.559431</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.382352</td>\n",
       "      <td>2</td>\n",
       "      <td>29.95</td>\n",
       "      <td>-0.417460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095600</td>\n",
       "      <td>-0.316853</td>\n",
       "      <td>-2.101403</td>\n",
       "      <td>-0.938609</td>\n",
       "      <td>0.162007</td>\n",
       "      <td>-2.101403</td>\n",
       "      <td>-0.384532</td>\n",
       "      <td>-0.059551</td>\n",
       "      <td>-0.824120</td>\n",
       "      <td>-0.181716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.320240</td>\n",
       "      <td>0.634964</td>\n",
       "      <td>0.099054</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>2</td>\n",
       "      <td>15.95</td>\n",
       "      <td>-0.227205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020426</td>\n",
       "      <td>1.007697</td>\n",
       "      <td>-0.542592</td>\n",
       "      <td>0.133260</td>\n",
       "      <td>-1.267933</td>\n",
       "      <td>-0.542592</td>\n",
       "      <td>0.982392</td>\n",
       "      <td>0.136926</td>\n",
       "      <td>-0.399634</td>\n",
       "      <td>-0.036166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stock  std_stock  family_id  subfamily_id  size_id  color_id  position  \\\n",
       "0 -0.282039   0.166092   0.125812      0.032623        5         1 -0.607923   \n",
       "1 -0.018691   0.457501   0.027100      0.002211        7         1 -0.257034   \n",
       "2 -0.213757   0.717466   0.007360      0.000577        6         1 -0.348934   \n",
       "3 -0.435951  -0.559431   0.049799      0.008652        3         1 -0.382352   \n",
       "4 -0.320240   0.634964   0.099054      0.021951        4         2  0.753861   \n",
       "\n",
       "   category_id  price  stock_lag1  ...        N2        N3        N5  \\\n",
       "0            2  25.95   -0.127604  ...  2.593296  3.400102 -2.880808   \n",
       "1            2  19.95    0.208348  ... -0.185230 -0.726099  0.236814   \n",
       "2            1  12.95   -0.197198  ... -0.792400 -0.950525  0.626516   \n",
       "3            2  29.95   -0.417460  ... -0.095600 -0.316853 -2.101403   \n",
       "4            2  15.95   -0.227205  ... -0.020426  1.007697 -0.542592   \n",
       "\n",
       "         N6        N7        N8        N9       N10       N12       N13  \n",
       "0 -1.474544  0.667705 -2.880808  4.454870  3.846410 -1.248607  3.361188  \n",
       "1  0.669195 -0.019229  0.236814 -0.559229 -0.397491 -0.116643 -0.355666  \n",
       "2 -2.010479 -0.233227  0.626516 -0.681823 -0.696136 -1.248607 -0.795867  \n",
       "3 -0.938609  0.162007 -2.101403 -0.384532 -0.059551 -0.824120 -0.181716  \n",
       "4  0.133260 -1.267933 -0.542592  0.982392  0.136926 -0.399634 -0.036166  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train.index\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = X_train.corr()\n",
    "\n",
    "# # plot the heatmap\n",
    "# sns.heatmap(corr, \n",
    "#         xticklabels=corr.columns,\n",
    "#         yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sample = X_train.fillna(-1).sample(frac=0.1)\n",
    "# X_fit, X_val, y_fit, y_val = train_test_split(X_train_sample,\n",
    "#                                               y_train.iloc[X_train_sample.index.values],\n",
    "#                                               test_size=0.25,\n",
    "#                                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'n_estimators': 500,\n",
    "#     'criterion': 'entropy',\n",
    "#     'max_depth': 10,\n",
    "#     'random_state': 42,\n",
    "#     'n_jobs': 8,\n",
    "#     'verbose': 0,\n",
    "#     'min_samples_leaf': 2,\n",
    "    \n",
    "# }\n",
    "\n",
    "# rf = RandomForestClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_refit = rf.fit(X_fit, y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm = PermutationImportance(rf_refit).fit(X_val, y_val)\n",
    "# show_weights(perm, feature_names=X_val.columns.tolist(), top=X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lgbm'\n",
    "\n",
    "params = {'max_depth':7,\n",
    "          'metric':'mae',\n",
    "          'max_delta_step': 0.2,\n",
    "          'n_estimators':50000,\n",
    "          'learning_rate':0.1,\n",
    "          'colsample_bytree':0.6,\n",
    "          'objective':'regression',\n",
    "          'n_jobs':8,\n",
    "          'seed':42,\n",
    "          'lambda_l1':0,\n",
    "          'lambda_l2':0,\n",
    "         }\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.460781\n",
      "[2000]\tvalid_0's l1: 0.44889\n",
      "[3000]\tvalid_0's l1: 0.444262\n",
      "[4000]\tvalid_0's l1: 0.442199\n",
      "Early stopping, best iteration is:\n",
      "[4023]\tvalid_0's l1: 0.442163\n",
      "--- Fold k 2:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.449542\n",
      "[2000]\tvalid_0's l1: 0.438252\n",
      "Early stopping, best iteration is:\n",
      "[2608]\tvalid_0's l1: 0.434846\n",
      "--- Fold k 3:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.459163\n",
      "[2000]\tvalid_0's l1: 0.446624\n",
      "Early stopping, best iteration is:\n",
      "[2500]\tvalid_0's l1: 0.443571\n",
      "--- Fold k 4:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.465724\n",
      "[2000]\tvalid_0's l1: 0.451477\n",
      "[3000]\tvalid_0's l1: 0.446751\n",
      "Early stopping, best iteration is:\n",
      "[3202]\tvalid_0's l1: 0.446432\n",
      "--- Fold k 5:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.451706\n",
      "[2000]\tvalid_0's l1: 0.438646\n",
      "Early stopping, best iteration is:\n",
      "[2926]\tvalid_0's l1: 0.434145\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    lgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=1000,\n",
    "                  early_stopping_rounds=50)\n",
    "\n",
    "    ft_importances += lgb_model.feature_importances_\n",
    "\n",
    "    be += np.expm1(lgb_model.best_score_['valid_0']['l1'])\n",
    "    y_preds = np.expm1(lgb_model.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "pr = pd.DataFrame({'predicciones_lightgbm_pw': full_preds})\n",
    "pr.to_csv('../predictions/week2/preds_lightgbm_pw.csv')\n",
    "\n",
    "# print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "# imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "# df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "# df_imp_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 7,\n",
    "          'metric':'mae',\n",
    "          'n_estimators': 5000,\n",
    "          'eta': 0.1,\n",
    "          'colsample_bytree':0.6,\n",
    "          'nthread':8,\n",
    "          'seed':42,\n",
    "          'objective':'reg:linear',\n",
    "         }\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n",
      "[0]\tvalidation_0-mae:2.50184\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.486368\n",
      "[200]\tvalidation_0-mae:0.468947\n",
      "[300]\tvalidation_0-mae:0.460369\n",
      "[400]\tvalidation_0-mae:0.455597\n",
      "[500]\tvalidation_0-mae:0.452297\n",
      "[600]\tvalidation_0-mae:0.450039\n",
      "[700]\tvalidation_0-mae:0.448176\n",
      "Stopping. Best iteration:\n",
      "[775]\tvalidation_0-mae:0.447056\n",
      "\n",
      "--- Fold k 2:\n",
      "[0]\tvalidation_0-mae:2.39973\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.47601\n",
      "[200]\tvalidation_0-mae:0.460235\n",
      "[300]\tvalidation_0-mae:0.451598\n",
      "[400]\tvalidation_0-mae:0.445823\n",
      "[500]\tvalidation_0-mae:0.443055\n",
      "[600]\tvalidation_0-mae:0.440452\n",
      "Stopping. Best iteration:\n",
      "[599]\tvalidation_0-mae:0.44044\n",
      "\n",
      "--- Fold k 3:\n",
      "[0]\tvalidation_0-mae:2.42152\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.482969\n",
      "[200]\tvalidation_0-mae:0.466274\n",
      "[300]\tvalidation_0-mae:0.457797\n",
      "[400]\tvalidation_0-mae:0.453683\n",
      "[500]\tvalidation_0-mae:0.449974\n",
      "Stopping. Best iteration:\n",
      "[552]\tvalidation_0-mae:0.449005\n",
      "\n",
      "--- Fold k 4:\n",
      "[0]\tvalidation_0-mae:2.57009\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.493862\n",
      "[200]\tvalidation_0-mae:0.474161\n",
      "[300]\tvalidation_0-mae:0.464399\n",
      "[400]\tvalidation_0-mae:0.45939\n",
      "[500]\tvalidation_0-mae:0.455988\n",
      "Stopping. Best iteration:\n",
      "[547]\tvalidation_0-mae:0.454913\n",
      "\n",
      "--- Fold k 5:\n",
      "[0]\tvalidation_0-mae:2.36856\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.478428\n",
      "[200]\tvalidation_0-mae:0.459237\n",
      "[300]\tvalidation_0-mae:0.449872\n",
      "[400]\tvalidation_0-mae:0.444661\n",
      "[500]\tvalidation_0-mae:0.441981\n",
      "[600]\tvalidation_0-mae:0.439735\n",
      "Stopping. Best iteration:\n",
      "[655]\tvalidation_0-mae:0.438875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    xgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=100,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_metric='mae')\n",
    "\n",
    "    ft_importances += xgb_model.feature_importances_\n",
    "\n",
    "    be += np.expm1(xgb_model.best_score)\n",
    "    y_preds = np.expm1(xgb_model.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "pr = pd.DataFrame({'predicciones_xgboost_pw': full_preds})\n",
    "pr.to_csv('../predictions/week2/preds_xgboost_pw.csv')\n",
    "\n",
    "# print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "# imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "# df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "# df_imp_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'depth':7,\n",
    "    'iterations':5000,\n",
    "    'eval_metric':'MAE',\n",
    "    'random_seed':42,\n",
    "    'early_stopping_rounds':[5],\n",
    "    'learning_rate':0.1,\n",
    "    'thread_count':8,\n",
    "    'boosting_type':'Plain',\n",
    "    'bootstrap_type':'Bernoulli',\n",
    "    'colsample_bylevel':0.6\n",
    "}\n",
    "\n",
    "model_cb = CatBoostRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n",
      "0:\tlearn: 2.7848288\ttest: 2.8493866\tbest: 2.8493866 (0)\ttotal: 79.6ms\tremaining: 6m 37s\n",
      "200:\tlearn: 0.4925311\ttest: 0.5189934\tbest: 0.5189934 (200)\ttotal: 2.18s\tremaining: 52.1s\n",
      "400:\tlearn: 0.4501711\ttest: 0.4918119\tbest: 0.4918119 (400)\ttotal: 4.38s\tremaining: 50.2s\n",
      "600:\tlearn: 0.4236170\ttest: 0.4787095\tbest: 0.4787095 (600)\ttotal: 6.66s\tremaining: 48.7s\n",
      "800:\tlearn: 0.4034469\ttest: 0.4706001\tbest: 0.4706001 (800)\ttotal: 8.83s\tremaining: 46.3s\n",
      "1000:\tlearn: 0.3868866\ttest: 0.4641995\tbest: 0.4641995 (1000)\ttotal: 11s\tremaining: 43.8s\n",
      "1200:\tlearn: 0.3717745\ttest: 0.4599124\tbest: 0.4599124 (1200)\ttotal: 13s\tremaining: 41.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4582121523\n",
      "bestIteration = 1299\n",
      "\n",
      "Shrink model to first 1300 iterations.\n",
      "--- Fold k 2:\n",
      "0:\tlearn: 2.8170982\ttest: 2.7479535\tbest: 2.7479535 (0)\ttotal: 10.5ms\tremaining: 52.6s\n",
      "200:\tlearn: 0.4968919\ttest: 0.5036974\tbest: 0.5036974 (200)\ttotal: 2.14s\tremaining: 51s\n",
      "400:\tlearn: 0.4536127\ttest: 0.4776428\tbest: 0.4776428 (400)\ttotal: 4.39s\tremaining: 50.4s\n",
      "600:\tlearn: 0.4266494\ttest: 0.4651668\tbest: 0.4651668 (600)\ttotal: 6.64s\tremaining: 48.6s\n",
      "800:\tlearn: 0.4062268\ttest: 0.4569131\tbest: 0.4569131 (800)\ttotal: 8.88s\tremaining: 46.6s\n",
      "1000:\tlearn: 0.3885226\ttest: 0.4511040\tbest: 0.4511040 (1000)\ttotal: 10.9s\tremaining: 43.6s\n",
      "1200:\tlearn: 0.3734989\ttest: 0.4475683\tbest: 0.4475683 (1200)\ttotal: 12.9s\tremaining: 40.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4472874238\n",
      "bestIteration = 1213\n",
      "\n",
      "Shrink model to first 1214 iterations.\n",
      "--- Fold k 3:\n",
      "0:\tlearn: 2.8035593\ttest: 2.7606420\tbest: 2.7606420 (0)\ttotal: 9.91ms\tremaining: 49.5s\n",
      "200:\tlearn: 0.4936543\ttest: 0.5133662\tbest: 0.5133662 (200)\ttotal: 2.02s\tremaining: 48.3s\n",
      "400:\tlearn: 0.4495293\ttest: 0.4861701\tbest: 0.4861701 (400)\ttotal: 4.04s\tremaining: 46.3s\n",
      "600:\tlearn: 0.4226908\ttest: 0.4733786\tbest: 0.4733786 (600)\ttotal: 6.06s\tremaining: 44.4s\n",
      "800:\tlearn: 0.4027842\ttest: 0.4661781\tbest: 0.4661781 (800)\ttotal: 8.08s\tremaining: 42.4s\n",
      "1000:\tlearn: 0.3862253\ttest: 0.4610017\tbest: 0.4609925 (999)\ttotal: 10.1s\tremaining: 40.3s\n",
      "1200:\tlearn: 0.3714667\ttest: 0.4566175\tbest: 0.4566175 (1200)\ttotal: 12.2s\tremaining: 38.6s\n",
      "1400:\tlearn: 0.3577508\ttest: 0.4530009\tbest: 0.4530009 (1400)\ttotal: 14.4s\tremaining: 36.9s\n",
      "1600:\tlearn: 0.3459699\ttest: 0.4507704\tbest: 0.4507704 (1600)\ttotal: 16.5s\tremaining: 35.1s\n",
      "1800:\tlearn: 0.3349716\ttest: 0.4485100\tbest: 0.4485100 (1800)\ttotal: 18.5s\tremaining: 32.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4481656215\n",
      "bestIteration = 1849\n",
      "\n",
      "Shrink model to first 1850 iterations.\n",
      "--- Fold k 4:\n",
      "0:\tlearn: 2.7664292\ttest: 2.9205193\tbest: 2.9205193 (0)\ttotal: 10ms\tremaining: 50.2s\n",
      "200:\tlearn: 0.4922934\ttest: 0.5240369\tbest: 0.5240369 (200)\ttotal: 2.02s\tremaining: 48.3s\n",
      "400:\tlearn: 0.4510082\ttest: 0.4946386\tbest: 0.4946386 (400)\ttotal: 4.15s\tremaining: 47.6s\n",
      "600:\tlearn: 0.4242825\ttest: 0.4798305\tbest: 0.4798305 (600)\ttotal: 6.29s\tremaining: 46s\n",
      "800:\tlearn: 0.4044687\ttest: 0.4719949\tbest: 0.4719830 (799)\ttotal: 8.93s\tremaining: 46.8s\n",
      "1000:\tlearn: 0.3874724\ttest: 0.4653095\tbest: 0.4653095 (1000)\ttotal: 11.1s\tremaining: 44.2s\n",
      "1200:\tlearn: 0.3732478\ttest: 0.4607681\tbest: 0.4607499 (1199)\ttotal: 13.2s\tremaining: 41.8s\n",
      "1400:\tlearn: 0.3600559\ttest: 0.4574175\tbest: 0.4573848 (1398)\ttotal: 15.3s\tremaining: 39.3s\n",
      "1600:\tlearn: 0.3479266\ttest: 0.4539910\tbest: 0.4539910 (1600)\ttotal: 17.4s\tremaining: 36.9s\n",
      "1800:\tlearn: 0.3366119\ttest: 0.4516469\tbest: 0.4516404 (1799)\ttotal: 19.4s\tremaining: 34.5s\n",
      "2000:\tlearn: 0.3264074\ttest: 0.4496108\tbest: 0.4496108 (2000)\ttotal: 21.5s\tremaining: 32.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4489047653\n",
      "bestIteration = 2065\n",
      "\n",
      "Shrink model to first 2066 iterations.\n",
      "--- Fold k 5:\n",
      "0:\tlearn: 2.8191370\ttest: 2.7094930\tbest: 2.7094930 (0)\ttotal: 11.2ms\tremaining: 55.8s\n",
      "200:\tlearn: 0.4963472\ttest: 0.5116466\tbest: 0.5116466 (200)\ttotal: 2.03s\tremaining: 48.5s\n",
      "400:\tlearn: 0.4543023\ttest: 0.4820149\tbest: 0.4820149 (400)\ttotal: 4.09s\tremaining: 47s\n",
      "600:\tlearn: 0.4286114\ttest: 0.4690034\tbest: 0.4690034 (600)\ttotal: 6.2s\tremaining: 45.4s\n",
      "800:\tlearn: 0.4086395\ttest: 0.4600643\tbest: 0.4600643 (800)\ttotal: 8.29s\tremaining: 43.5s\n",
      "1000:\tlearn: 0.3912935\ttest: 0.4542852\tbest: 0.4542852 (1000)\ttotal: 10.4s\tremaining: 41.5s\n",
      "1200:\tlearn: 0.3761238\ttest: 0.4495473\tbest: 0.4495400 (1198)\ttotal: 12.4s\tremaining: 39.3s\n",
      "1400:\tlearn: 0.3628636\ttest: 0.4463328\tbest: 0.4463328 (1400)\ttotal: 14.4s\tremaining: 37.1s\n",
      "1600:\tlearn: 0.3504807\ttest: 0.4433759\tbest: 0.4433759 (1600)\ttotal: 16.5s\tremaining: 35.1s\n",
      "1800:\tlearn: 0.3390907\ttest: 0.4408859\tbest: 0.4408786 (1799)\ttotal: 18.6s\tremaining: 33s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4399348968\n",
      "bestIteration = 1874\n",
      "\n",
      "Shrink model to first 1875 iterations.\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    model_cb.fit(X_fit,\n",
    "                 y_fit,\n",
    "                 eval_set=[(X_val, y_val)],\n",
    "                 verbose=200,\n",
    "#                  cat_features=cat_ft_id,\n",
    "                 early_stopping_rounds=10)\n",
    "\n",
    "    ft_importances += model_cb.feature_importances_\n",
    "\n",
    "    be += np.expm1(model_cb.best_score_['validation_0']['MAE'])\n",
    "    y_preds = np.expm1(model_cb.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "pr = pd.DataFrame({'predicciones_catboost_pw': full_preds})\n",
    "pr.to_csv('../predictions/week2/preds_catboost_pw.csv')\n",
    "\n",
    "# print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "# imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "# df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "# df_imp_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = X_train.fillna(-1)#.sample(frac=0.1)\n",
    "X_fit, X_val, y_fit, y_val = train_test_split(X_train_sample,\n",
    "                                              y_train.iloc[X_train_sample.index.values],\n",
    "                                              test_size=0.25,\n",
    "                                              random_state=42)\n",
    "\n",
    "y_val = np.log1p(y_val)\n",
    "y_fit = np.log1p(y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=0.0,\n",
    "                           patience=3,\n",
    "                           verbose=1,\n",
    "                           mode='min',\n",
    "                           restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(512, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.add(Masking(mask_value=-1))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=create_baseline,\n",
    "                           epochs=100,\n",
    "                           batch_size=1024,\n",
    "                           verbose=1,\n",
    "                           callbacks=callbacks,\n",
    "                           validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53986 samples, validate on 12954 samples\n",
      "Epoch 1/100\n",
      "53986/53986 [==============================] - 3s 57us/step - loss: 71.5701 - val_loss: 40.5570\n",
      "Epoch 2/100\n",
      "53986/53986 [==============================] - 2s 41us/step - loss: 56.9466 - val_loss: 39.2343\n",
      "Epoch 3/100\n",
      "53986/53986 [==============================] - 2s 41us/step - loss: 54.9822 - val_loss: 39.2244\n",
      "Epoch 4/100\n",
      "53986/53986 [==============================] - 2s 42us/step - loss: 53.6224 - val_loss: 38.5947\n",
      "Epoch 5/100\n",
      "53986/53986 [==============================] - 2s 42us/step - loss: 51.8336 - val_loss: 35.3132\n",
      "Epoch 6/100\n",
      "53986/53986 [==============================] - 2s 41us/step - loss: 50.3344 - val_loss: 35.2626\n",
      "Epoch 7/100\n",
      "53986/53986 [==============================] - 2s 42us/step - loss: 49.2566 - val_loss: 33.7970\n",
      "Epoch 8/100\n",
      "53986/53986 [==============================] - 2s 42us/step - loss: 49.0929 - val_loss: 35.3010\n",
      "Epoch 9/100\n",
      "53986/53986 [==============================] - 2s 43us/step - loss: 47.8999 - val_loss: 34.8923\n",
      "Epoch 10/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 47.1209 - val_loss: 33.6530\n",
      "Epoch 11/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 46.7636 - val_loss: 33.3094\n",
      "Epoch 12/100\n",
      "53986/53986 [==============================] - 3s 48us/step - loss: 46.4143 - val_loss: 32.3359\n",
      "Epoch 13/100\n",
      "53986/53986 [==============================] - 2s 46us/step - loss: 45.3639 - val_loss: 32.8050\n",
      "Epoch 14/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 45.1525 - val_loss: 32.9323\n",
      "Epoch 15/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 44.2993 - val_loss: 31.9422\n",
      "Epoch 16/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 44.0998 - val_loss: 32.4332\n",
      "Epoch 17/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 44.2286 - val_loss: 32.4143\n",
      "Epoch 18/100\n",
      "53986/53986 [==============================] - 3s 49us/step - loss: 43.1077 - val_loss: 32.8448\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = estimator.fit(X_fit, y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8892/8892 [==============================] - 0s 42us/step\n"
     ]
    }
   ],
   "source": [
    "keras_preds = estimator.predict(X_test.fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6985578e+22, 6.4428597e+23, 8.6390270e+11, 8.6514801e+01,\n",
       "       2.7918719e+26,           inf,           inf, 8.3036050e-02,\n",
       "       1.2666060e+06, 8.2322948e+34, 4.8008733e+00, 4.0634163e+09,\n",
       "       1.2145674e+02, 1.6532171e+00,           inf, 2.4927830e+32,\n",
       "       2.1460220e+25, 1.0394682e+07, 2.5452344e+05, 3.0771423e+24],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(keras_preds)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "ridge = Ridge(alpha=100,\n",
    "              fit_intercept=True,\n",
    "              normalize=False,\n",
    "              copy_X=True,\n",
    "              max_iter=1e6,\n",
    "              tol=0.01,\n",
    "              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold k 1\n",
      "\n",
      "Score en el test: 64.88086937583938 ventas\n",
      "Fold k 2\n",
      "\n",
      "Score en el test: 54.13480765738701 ventas\n",
      "Fold k 3\n",
      "\n",
      "Score en el test: 57.697222867256 ventas\n",
      "Fold k 4\n",
      "\n",
      "Score en el test: 95.66856823488475 ventas\n",
      "Fold k 5\n",
      "\n",
      "Score en el test: 54.505076034070875 ventas\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('Fold k {}\\n'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    X_fit = X_fit.fillna(-1)\n",
    "    X_val = X_val.fillna(-1)\n",
    "    \n",
    "#     y_val = np.log1p(y_val)\n",
    "#     y_fit = np.log1p(y_fit)\n",
    "    \n",
    "    ridge.fit(X_fit, y_fit)\n",
    "    \n",
    "    print('Score en el test:',mean_absolute_error(ridge.predict(X_val), y_val),'ventas')\n",
    "#     print('Score en el test:',mean_absolute_error(np.expm1(lasso.predict(X_test.fillna(-1))), y_test),'ventas')\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    \n",
    "# print('\\n\\nBEST SCORE MEAN:', be / k,'SALES :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score en el test: 14.756823797072453 ventas\n",
      "Score en el test: 14.100715922865659 ventas\n",
      "Score en el test: 12.151307647028101 ventas\n",
      "Score en el test: 51.86876752206717 ventas\n",
      "Score en el test: 71.48256121213558 ventas\n",
      "Score en el test: 71.92217457062922 ventas\n",
      "Score en el test: 68.28141522284636 ventas\n",
      "Score en el test: 70.27419173579888 ventas\n",
      "Score en el test: 68.17364411398036 ventas\n",
      "Score en el test: 68.03255886397835 ventas\n",
      "Score en el test: 67.67764600238846 ventas\n",
      "Score en el test: 67.92744267608478 ventas\n",
      "Score en el test: 60.29241413900714 ventas\n",
      "Score en el test: 73.54090753222067 ventas\n",
      "Score en el test: 98.75496060857435 ventas\n",
      "Score en el test: 101.1358736415784 ventas\n",
      "Score en el test: 94.34493406037016 ventas\n",
      "Score en el test: 89.109853582185 ventas\n",
      "Score en el test: 94.87292021432982 ventas\n",
      "Score en el test: 101.50598193500386 ventas\n",
      "Score en el test: 83.5619960969 ventas\n",
      "Score en el test: 82.39001244804034 ventas\n",
      "Score en el test: 79.99393026544735 ventas\n",
      "Score en el test: 69.05517201811276 ventas\n",
      "Score en el test: 75.39925338460172 ventas\n",
      "Score en el test: 74.36319513002407 ventas\n",
      "Score en el test: 67.22396383096311 ventas\n",
      "Score en el test: 67.85436268596388 ventas\n",
      "Score en el test: 74.61815992422738 ventas\n",
      "Score en el test: 68.06128670898939 ventas\n",
      "Score en el test: 72.33887535656895 ventas\n",
      "Score en el test: 70.29216019183501 ventas\n",
      "Score en el test: 81.22020530495422 ventas\n",
      "Score en el test: 61.87964993881166 ventas\n",
      "Score en el test: 67.80441667877402 ventas\n",
      "Score en el test: 72.19305653389645 ventas\n",
      "Score en el test: 58.85607550345796 ventas\n",
      "Score en el test: 64.08785036422316 ventas\n",
      "Score en el test: 70.77121186590314 ventas\n",
      "Score en el test: 72.21325343027388 ventas\n",
      "Score en el test: 76.35200226669929 ventas\n",
      "Score en el test: 64.68623982362757 ventas\n",
      "Score en el test: 66.504362465678 ventas\n",
      "Score en el test: 53.27655276424894 ventas\n",
      "Score en el test: 64.82435387763033 ventas\n",
      "Score en el test: 63.339900427294054 ventas\n",
      "Score en el test: 66.9712207390014 ventas\n",
      "Score en el test: 71.03898290086933 ventas\n",
      "Score en el test: 73.56998264783722 ventas\n",
      "Score en el test: 60.49236753667905 ventas\n",
      "Score en el test: 60.35686257938372 ventas\n",
      "Score en el test: 63.923448725303864 ventas\n",
      "Score en el test: 58.06525113389149 ventas\n",
      "Score en el test: 64.2718073342924 ventas\n",
      "Score en el test: 61.613301526332485 ventas\n",
      "Score en el test: 63.80576215676884 ventas\n",
      "Score en el test: 61.064446709285484 ventas\n",
      "Score en el test: 62.21291398207712 ventas\n",
      "Score en el test: 58.2944098984143 ventas\n",
      "Score en el test: 62.351817467363965 ventas\n",
      "Score en el test: 59.14517604544217 ventas\n",
      "Score en el test: 62.42236745944205 ventas\n",
      "Score en el test: 57.73512971036944 ventas\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    X_fit = X_fit.fillna(-1)\n",
    "    X_val = X_val.fillna(-1)\n",
    "    \n",
    "#     y_val = np.log1p(y_val)\n",
    "#     y_fit = np.log1p(y_fit)\n",
    "    \n",
    "    \n",
    "    ridge.fit(X_fit,\n",
    "                  y_fit,\n",
    "#                   eval_set=[(X_val, y_val)],\n",
    "#                   verbose=1000,\n",
    "#                   early_stopping_rounds=20\n",
    "             )\n",
    "    \n",
    "    print('Score en el test:',mean_absolute_error(ridge.predict(X_val), y_val),'ventas')\n",
    "\n",
    "#     be += np.expm1(lgb_model.best_score_['valid_0']['l1'])\n",
    "#     be += lgb_model.best_score_['valid_0']['l1']\n",
    "    \n",
    "#     print('Score en el test:',mean_absolute_error(lgb_model.predict(X_test), y_test),'ventas')\n",
    "#     print('Score en el test:',mean_absolute_error(np.expm1(lgb_model.predict(X_test)), y_test),'ventas')\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
