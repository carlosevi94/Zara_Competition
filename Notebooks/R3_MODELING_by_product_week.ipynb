{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from eli5 import show_weights, show_prediction\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Masking\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/final_train_pw.csv')\n",
    "test = pd.read_csv('../data/final_test_pw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>position</th>\n",
       "      <th>category_id</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310130</td>\n",
       "      <td>1726</td>\n",
       "      <td>1383</td>\n",
       "      <td>34.811328</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6184</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1178388</td>\n",
       "      <td>592</td>\n",
       "      <td>60</td>\n",
       "      <td>2.160247</td>\n",
       "      <td>0.049343</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>412</td>\n",
       "      <td>756</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10634</td>\n",
       "      <td>10</td>\n",
       "      <td>208</td>\n",
       "      <td>129</td>\n",
       "      <td>10</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1561460</td>\n",
       "      <td>1625</td>\n",
       "      <td>2373</td>\n",
       "      <td>55.438769</td>\n",
       "      <td>0.123499</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>1577</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8208</td>\n",
       "      <td>10</td>\n",
       "      <td>1130</td>\n",
       "      <td>380</td>\n",
       "      <td>12</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1874414</td>\n",
       "      <td>1135</td>\n",
       "      <td>1686</td>\n",
       "      <td>20.463906</td>\n",
       "      <td>0.110920</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>445</td>\n",
       "      <td>954</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5295</td>\n",
       "      <td>10</td>\n",
       "      <td>268</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2436420</td>\n",
       "      <td>779</td>\n",
       "      <td>245</td>\n",
       "      <td>23.377339</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>296</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8208</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  block_id  stock  std_stock  family_id  subfamily_id  size_id  \\\n",
       "0      310130      1726   1383  34.811328   0.007081      0.000583        7   \n",
       "1     1178388       592     60   2.160247   0.049343      0.012578        4   \n",
       "2     1561460      1625   2373  55.438769   0.123499      0.023558        5   \n",
       "3     1874414      1135   1686  20.463906   0.110920      0.016119        6   \n",
       "4     2436420       779    245  23.377339   0.025814      0.004422        5   \n",
       "\n",
       "   color_id  position  category_id  ...   N2    N3  N5  N6     N7  N8    N9  \\\n",
       "0         1       3.0            3  ...   13    39  10  10   6184  10    10   \n",
       "1         1      19.0            1  ...  412   756  10  10  10634  10   208   \n",
       "2         1      38.0            3  ...  480  1577  10  10   8208  10  1130   \n",
       "3         1      12.0            6  ...  445   954  10  10   5295  10   268   \n",
       "4         1       NaN            0  ...  151   296  10  10   8208  10    27   \n",
       "\n",
       "   N10  N12  N13  \n",
       "0   10   17   13  \n",
       "1  129   10  412  \n",
       "2  380   12  480  \n",
       "3   69   10  423  \n",
       "4   17   19  151  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_number</th>\n",
       "      <th>product_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>position_max</th>\n",
       "      <th>...</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>151926</td>\n",
       "      <td>1969</td>\n",
       "      <td>636</td>\n",
       "      <td>33.103206</td>\n",
       "      <td>0.131242</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2198</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8113</td>\n",
       "      <td>7</td>\n",
       "      <td>1169</td>\n",
       "      <td>413</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>213413</td>\n",
       "      <td>1648</td>\n",
       "      <td>1190</td>\n",
       "      <td>36.225788</td>\n",
       "      <td>0.034750</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>...</td>\n",
       "      <td>196</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5145</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>310130</td>\n",
       "      <td>1726</td>\n",
       "      <td>442</td>\n",
       "      <td>52.809180</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5145</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>455200</td>\n",
       "      <td>1400</td>\n",
       "      <td>86</td>\n",
       "      <td>6.831301</td>\n",
       "      <td>0.043185</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>287</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6391</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "      <td>571044</td>\n",
       "      <td>1098</td>\n",
       "      <td>416</td>\n",
       "      <td>42.178063</td>\n",
       "      <td>0.103014</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>205.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1036</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1673</td>\n",
       "      <td>7</td>\n",
       "      <td>441</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_number  product_id  block_id  stock  std_stock  family_id  \\\n",
       "0           71      151926      1969    636  33.103206   0.131242   \n",
       "1           71      213413      1648   1190  36.225788   0.034750   \n",
       "2           71      310130      1726    442  52.809180   0.008210   \n",
       "3           71      455200      1400     86   6.831301   0.043185   \n",
       "4           71      571044      1098    416  42.178063   0.103014   \n",
       "\n",
       "   subfamily_id  size_id  color_id  position_max  ...    N3  N5  N6    N7  N8  \\\n",
       "0      0.035875        5         1          22.0  ...  2198   7   7  8113   7   \n",
       "1      0.003149        7         1         139.0  ...   196   7   7  5145   7   \n",
       "2      0.000562        7         1          46.0  ...    35   7   7  5145   7   \n",
       "3      0.007647        3         1          53.0  ...   287   7   7  6391   7   \n",
       "4      0.023392        4         2         205.0  ...  1036   7   7  1673   7   \n",
       "\n",
       "     N9  N10  N11  N12  N13  \n",
       "0  1169  413   59    7  615  \n",
       "1    42   28    4    7   80  \n",
       "2     7    7    1    7   10  \n",
       "3    63   49    7    7   75  \n",
       "4   441   98   14    7  145  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['sales', 'date_number', 'product_id', 'block_id']\n",
    "\n",
    "X_train = train.loc[:,[c for c in train.columns if c not in drop_cols]]\n",
    "y_train = train[['sales']]\n",
    "X_test = test.loc[:,[c for c in train.columns if c not in drop_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarización de las variables para modelos lineales y redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ss = ['stock', 'std_stock', 'position', 'stock_lag1',\n",
    "       'stock_lead1', 'std_stock_shift1', 'mean_stock_shift1',\n",
    "       'min_stock_shift1', 'max_stock_shift1', 'median_stock_shift1',\n",
    "       'stock_lag2', 'stock_lead2', 'std_stock_shift2', 'min_stock_shift2',\n",
    "       'max_stock_shift2', 'median_stock_shift2', 'mean_stock_shift2',\n",
    "       'pos_lag1', 'pos_lead1', 'std_pos_shift1', 'mean_pos_shift1',\n",
    "       'min_pos_shift1', 'max_pos_shift1', 'median_pos_shift1', 'pos_lag2',\n",
    "       'pos_lead2', 'std_pos_shift2', 'min_pos_shift2', 'max_pos_shift2',\n",
    "       'median_pos_shift2', 'mean_pos_shift2', 'diff_stock_lead1',\n",
    "       'diff_stock_lead2', 'diff_stock_lag1', 'diff_stock_lag2',\n",
    "       'diff_pos_lead1', 'diff_pos_lead2', 'diff_pos_lag1', 'diff_pos_lag2',\n",
    "       'std_stock_shift3', 'mean_stock_shift3', 'min_stock_shift3',\n",
    "       'max_stock_shift3', 'median_stock_shift3', 'std_pos_shift3',\n",
    "       'mean_pos_shift3', 'min_pos_shift3', 'max_pos_shift3',\n",
    "       'median_pos_shift3', 'ratio_position',\n",
    "       'N1', 'N2', 'N3', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'N12', 'N13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/errodringer/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train[cols_ss])\n",
    "X_train[cols_ss] = ss.transform(X_train[cols_ss])\n",
    "X_test[cols_ss] = ss.transform(X_test[cols_ss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>position</th>\n",
       "      <th>category_id</th>\n",
       "      <th>price</th>\n",
       "      <th>stock_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.232097</td>\n",
       "      <td>0.279538</td>\n",
       "      <td>0.131242</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.733198</td>\n",
       "      <td>2</td>\n",
       "      <td>25.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334701</td>\n",
       "      <td>-0.378972</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-2.249975</td>\n",
       "      <td>-1.440403</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>-0.065407</td>\n",
       "      <td>-1.669897</td>\n",
       "      <td>-0.218442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.015572</td>\n",
       "      <td>0.441419</td>\n",
       "      <td>0.034750</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.251464</td>\n",
       "      <td>2</td>\n",
       "      <td>19.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.752467</td>\n",
       "      <td>-0.988306</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-2.249975</td>\n",
       "      <td>-1.566137</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-0.696751</td>\n",
       "      <td>-0.677841</td>\n",
       "      <td>-1.669897</td>\n",
       "      <td>-0.763263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.182891</td>\n",
       "      <td>0.839566</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353369</td>\n",
       "      <td>1</td>\n",
       "      <td>12.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825474</td>\n",
       "      <td>-1.037309</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-2.249975</td>\n",
       "      <td>-1.566137</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-0.718579</td>\n",
       "      <td>-0.711247</td>\n",
       "      <td>-1.669897</td>\n",
       "      <td>-0.834548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.433461</td>\n",
       "      <td>-0.552137</td>\n",
       "      <td>0.043185</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.288520</td>\n",
       "      <td>2</td>\n",
       "      <td>29.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760579</td>\n",
       "      <td>-0.960609</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-2.249975</td>\n",
       "      <td>-1.513352</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-0.683654</td>\n",
       "      <td>-0.644436</td>\n",
       "      <td>-1.669897</td>\n",
       "      <td>-0.768355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.306996</td>\n",
       "      <td>0.572720</td>\n",
       "      <td>0.103014</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.647156</td>\n",
       "      <td>2</td>\n",
       "      <td>15.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.691627</td>\n",
       "      <td>-0.732642</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-2.249975</td>\n",
       "      <td>-1.713222</td>\n",
       "      <td>-3.772139</td>\n",
       "      <td>-0.447910</td>\n",
       "      <td>-0.566490</td>\n",
       "      <td>-1.669897</td>\n",
       "      <td>-0.697070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stock  std_stock  family_id  subfamily_id  size_id  color_id  position  \\\n",
       "0 -0.232097   0.279538   0.131242      0.035875        5         1 -0.733198   \n",
       "1 -0.015572   0.441419   0.034750      0.003149        7         1 -0.251464   \n",
       "2 -0.182891   0.839566   0.008210      0.000562        7         1 -0.353369   \n",
       "3 -0.433461  -0.552137   0.043185      0.007647        3         1 -0.288520   \n",
       "4 -0.306996   0.572720   0.103014      0.023392        4         2  0.647156   \n",
       "\n",
       "   category_id  price  stock_lag1  ...        N2        N3        N5  \\\n",
       "0            2  25.95         NaN  ... -0.334701 -0.378972 -3.772139   \n",
       "1            2  19.95         NaN  ... -0.752467 -0.988306 -3.772139   \n",
       "2            1  12.95         NaN  ... -0.825474 -1.037309 -3.772139   \n",
       "3            2  29.95         NaN  ... -0.760579 -0.960609 -3.772139   \n",
       "4            2  15.95         NaN  ... -0.691627 -0.732642 -3.772139   \n",
       "\n",
       "         N6        N7        N8        N9       N10       N12       N13  \n",
       "0 -2.249975 -1.440403 -3.772139  0.006116 -0.065407 -1.669897 -0.218442  \n",
       "1 -2.249975 -1.566137 -3.772139 -0.696751 -0.677841 -1.669897 -0.763263  \n",
       "2 -2.249975 -1.566137 -3.772139 -0.718579 -0.711247 -1.669897 -0.834548  \n",
       "3 -2.249975 -1.513352 -3.772139 -0.683654 -0.644436 -1.669897 -0.768355  \n",
       "4 -2.249975 -1.713222 -3.772139 -0.447910 -0.566490 -1.669897 -0.697070  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train.index\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = X_train.corr()\n",
    "\n",
    "# # plot the heatmap\n",
    "# sns.heatmap(corr, \n",
    "#         xticklabels=corr.columns,\n",
    "#         yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sample = X_train.fillna(-1).sample(frac=0.1)\n",
    "# X_fit, X_val, y_fit, y_val = train_test_split(X_train_sample,\n",
    "#                                               y_train.iloc[X_train_sample.index.values],\n",
    "#                                               test_size=0.25,\n",
    "#                                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'n_estimators': 500,\n",
    "#     'criterion': 'entropy',\n",
    "#     'max_depth': 10,\n",
    "#     'random_state': 42,\n",
    "#     'n_jobs': 8,\n",
    "#     'verbose': 0,\n",
    "#     'min_samples_leaf': 2,\n",
    "    \n",
    "# }\n",
    "\n",
    "# rf = RandomForestClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_refit = rf.fit(X_fit, y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm = PermutationImportance(rf_refit).fit(X_val, y_val)\n",
    "# show_weights(perm, feature_names=X_val.columns.tolist(), top=X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lgbm'\n",
    "\n",
    "params = {'max_depth':7,\n",
    "          'metric':'mae',\n",
    "          'max_delta_step': 0.2,\n",
    "          'n_estimators':50000,\n",
    "          'learning_rate':0.1,\n",
    "          'colsample_bytree':0.6,\n",
    "          'objective':'regression',\n",
    "          'n_jobs':8,\n",
    "          'seed':42,\n",
    "          'lambda_l1':0,\n",
    "          'lambda_l2':0,\n",
    "#           'max_bin': 14,\n",
    "#           'bagging_fraction':0.8,\n",
    "         }\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.459195\n",
      "[2000]\tvalid_0's l1: 0.450289\n",
      "Early stopping, best iteration is:\n",
      "[2049]\tvalid_0's l1: 0.450113\n",
      "--- Fold k 2:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.455623\n",
      "[2000]\tvalid_0's l1: 0.444586\n",
      "Early stopping, best iteration is:\n",
      "[2534]\tvalid_0's l1: 0.441586\n",
      "--- Fold k 3:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.464977\n",
      "[2000]\tvalid_0's l1: 0.454338\n",
      "Early stopping, best iteration is:\n",
      "[2920]\tvalid_0's l1: 0.450841\n",
      "--- Fold k 4:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.466662\n",
      "[2000]\tvalid_0's l1: 0.453884\n",
      "Early stopping, best iteration is:\n",
      "[2480]\tvalid_0's l1: 0.451058\n",
      "--- Fold k 5:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.459266\n",
      "[2000]\tvalid_0's l1: 0.447861\n",
      "Early stopping, best iteration is:\n",
      "[2633]\tvalid_0's l1: 0.445152\n",
      "IMPORTANCIA DE LAS VARIABLES:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std_stock</td>\n",
       "      <td>2797.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>diff_stock_lead1</td>\n",
       "      <td>2550.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>diff_stock_lead2</td>\n",
       "      <td>2320.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>diff_stock_lag1</td>\n",
       "      <td>2069.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stock_lead2</td>\n",
       "      <td>1796.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>N9</td>\n",
       "      <td>1794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std_stock_shift1</td>\n",
       "      <td>1769.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>std_stock_shift2</td>\n",
       "      <td>1739.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>diff_stock_lag2</td>\n",
       "      <td>1619.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>N10</td>\n",
       "      <td>1573.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>price</td>\n",
       "      <td>1566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subfamily_id</td>\n",
       "      <td>1548.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>min_stock_shift3</td>\n",
       "      <td>1504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>std_pos_shift2</td>\n",
       "      <td>1449.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>std_pos_shift1</td>\n",
       "      <td>1432.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>N3</td>\n",
       "      <td>1405.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>min_stock_shift2</td>\n",
       "      <td>1397.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>N1</td>\n",
       "      <td>1375.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stock_lead1</td>\n",
       "      <td>1357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>diff_pos_lead2</td>\n",
       "      <td>1301.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stock_lag1</td>\n",
       "      <td>1291.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>N12</td>\n",
       "      <td>1274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>N13</td>\n",
       "      <td>1270.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stock_lag2</td>\n",
       "      <td>1266.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family_id</td>\n",
       "      <td>1255.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pos_lead2</td>\n",
       "      <td>1204.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>diff_pos_lead1</td>\n",
       "      <td>1192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>diff_pos_lag1</td>\n",
       "      <td>1144.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>std_pos_shift3</td>\n",
       "      <td>1106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>diff_pos_lag2</td>\n",
       "      <td>1099.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>median_stock_shift2</td>\n",
       "      <td>958.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stock</td>\n",
       "      <td>951.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>category_id</td>\n",
       "      <td>941.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>max_pos_shift2</td>\n",
       "      <td>908.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pos_lag1</td>\n",
       "      <td>906.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mean_stock_shift3</td>\n",
       "      <td>848.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>median_stock_shift1</td>\n",
       "      <td>776.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max_stock_shift1</td>\n",
       "      <td>758.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>N6</td>\n",
       "      <td>747.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>min_pos_shift1</td>\n",
       "      <td>734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mean_pos_shift2</td>\n",
       "      <td>725.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>N7</td>\n",
       "      <td>723.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>size_d_color</td>\n",
       "      <td>721.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mean_stock_shift2</td>\n",
       "      <td>718.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>size_p_color</td>\n",
       "      <td>685.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>median_pos_shift2</td>\n",
       "      <td>652.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>max_pos_shift1</td>\n",
       "      <td>634.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_stock_shift1</td>\n",
       "      <td>628.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>N5</td>\n",
       "      <td>627.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>median_pos_shift3</td>\n",
       "      <td>616.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mean_pos_shift1</td>\n",
       "      <td>602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mean_pos_shift3</td>\n",
       "      <td>568.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>size_id</td>\n",
       "      <td>524.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>N2</td>\n",
       "      <td>518.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>median_pos_shift1</td>\n",
       "      <td>462.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>max_stock_shift3</td>\n",
       "      <td>439.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>max_pos_shift3</td>\n",
       "      <td>366.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ratio_position</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>N8</td>\n",
       "      <td>261.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>color_id</td>\n",
       "      <td>145.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  importance\n",
       "1             std_stock      2797.6\n",
       "37     diff_stock_lead1      2550.4\n",
       "38     diff_stock_lead2      2320.8\n",
       "39      diff_stock_lag1      2069.6\n",
       "17          stock_lead2      1796.6\n",
       "65                   N9      1794.0\n",
       "11     std_stock_shift1      1769.6\n",
       "18     std_stock_shift2      1739.6\n",
       "40      diff_stock_lag2      1619.6\n",
       "66                  N10      1573.8\n",
       "8                 price      1566.0\n",
       "3          subfamily_id      1548.6\n",
       "47     min_stock_shift3      1504.0\n",
       "32       std_pos_shift2      1449.4\n",
       "25       std_pos_shift1      1432.2\n",
       "60                   N3      1405.6\n",
       "19     min_stock_shift2      1397.8\n",
       "58                   N1      1375.8\n",
       "10          stock_lead1      1357.0\n",
       "42       diff_pos_lead2      1301.4\n",
       "9            stock_lag1      1291.4\n",
       "67                  N12      1274.0\n",
       "68                  N13      1270.6\n",
       "16           stock_lag2      1266.4\n",
       "2             family_id      1255.4\n",
       "31            pos_lead2      1204.4\n",
       "41       diff_pos_lead1      1192.0\n",
       "43        diff_pos_lag1      1144.2\n",
       "50       std_pos_shift3      1106.2\n",
       "44        diff_pos_lag2      1099.6\n",
       "..                  ...         ...\n",
       "21  median_stock_shift2       958.2\n",
       "0                 stock       951.4\n",
       "7           category_id       941.8\n",
       "34       max_pos_shift2       908.8\n",
       "23             pos_lag1       906.6\n",
       "46    mean_stock_shift3       848.6\n",
       "15  median_stock_shift1       776.4\n",
       "14     max_stock_shift1       758.6\n",
       "62                   N6       747.8\n",
       "27       min_pos_shift1       734.0\n",
       "36      mean_pos_shift2       725.8\n",
       "63                   N7       723.8\n",
       "56         size_d_color       721.4\n",
       "22    mean_stock_shift2       718.8\n",
       "55         size_p_color       685.8\n",
       "35    median_pos_shift2       652.2\n",
       "28       max_pos_shift1       634.8\n",
       "12    mean_stock_shift1       628.4\n",
       "61                   N5       627.4\n",
       "54    median_pos_shift3       616.4\n",
       "26      mean_pos_shift1       602.0\n",
       "51      mean_pos_shift3       568.4\n",
       "4               size_id       524.2\n",
       "59                   N2       518.4\n",
       "29    median_pos_shift1       462.8\n",
       "48     max_stock_shift3       439.8\n",
       "53       max_pos_shift3       366.6\n",
       "57       ratio_position       299.0\n",
       "64                   N8       261.6\n",
       "5              color_id       145.6\n",
       "\n",
       "[69 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    lgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=1000,\n",
    "                  early_stopping_rounds=50)\n",
    "\n",
    "    ft_importances += lgb_model.feature_importances_\n",
    "\n",
    "    be += np.expm1(lgb_model.best_score_['valid_0']['l1'])\n",
    "    y_preds = np.expm1(lgb_model.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "pr = pd.DataFrame({'predicciones_lightgbm_pw': full_preds})\n",
    "pr.to_csv('../predictions/preds_lightgbm_pw.csv')\n",
    "\n",
    "print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "df_imp_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 7,\n",
    "          'metric':'mae',\n",
    "          'n_estimators': 5000,\n",
    "          'eta': 0.1,\n",
    "          'colsample_bytree':0.6,\n",
    "          'nthread':8,\n",
    "          'seed':42,\n",
    "          'objective':'reg:linear',\n",
    "#           'update':'refresh',\n",
    "#           'process_type': 'update',\n",
    "#           'refresh_leaf': True,\n",
    "         }\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "b'[20:15:16] /workspace/src/gbm/gbtree.cc:290: Check failed: model_.trees.size() < model_.trees_to_update.size() (0 vs. 0) \\n\\nStack trace returned 10 entries:\\n[bt] (0) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(dmlc::StackTrace()+0x3d) [0x7f04e27b45cd]\\n[bt] (1) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x18) [0x7f04e27b49c8]\\n[bt] (2) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::BoostNewTrees(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, int, std::vector<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> >, std::allocator<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> > > >*)+0x8f6) [0x7f04e28870a6]\\n[bt] (3) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::DoBoost(xgboost::DMatrix*, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::ObjFunction*)+0x90e) [0x7f04e2887b1e]\\n[bt] (4) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x3b8) [0x7f04e282b238]\\n[bt] (5) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7f04e27acab5]\\n[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f052d148dae]\\n[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7f052d14871f]\\n[bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2b4) [0x7f052d35c524]\\n[bt] (9) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x11b93) [0x7f052d35cb93]\\n\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-faa18713f508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                   \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                   eval_metric='mae')\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mft_importances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    371\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1045\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: b'[20:15:16] /workspace/src/gbm/gbtree.cc:290: Check failed: model_.trees.size() < model_.trees_to_update.size() (0 vs. 0) \\n\\nStack trace returned 10 entries:\\n[bt] (0) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(dmlc::StackTrace()+0x3d) [0x7f04e27b45cd]\\n[bt] (1) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x18) [0x7f04e27b49c8]\\n[bt] (2) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::BoostNewTrees(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, int, std::vector<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> >, std::allocator<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> > > >*)+0x8f6) [0x7f04e28870a6]\\n[bt] (3) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::DoBoost(xgboost::DMatrix*, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::ObjFunction*)+0x90e) [0x7f04e2887b1e]\\n[bt] (4) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x3b8) [0x7f04e282b238]\\n[bt] (5) /home/errodringer/.local/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7f04e27acab5]\\n[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f052d148dae]\\n[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7f052d14871f]\\n[bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2b4) [0x7f052d35c524]\\n[bt] (9) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x11b93) [0x7f052d35cb93]\\n\\n'"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    xgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=100,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_metric='mae')\n",
    "\n",
    "    ft_importances += xgb_model.feature_importances_\n",
    "\n",
    "    be += np.expm1(xgb_model.best_score)\n",
    "    y_preds = np.expm1(xgb_model.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "# pr = pd.DataFrame({'predicciones_xgboost_pw': full_preds})\n",
    "# pr.to_csv('../predictions/preds_xgboost_pw.csv')\n",
    "\n",
    "print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "df_imp_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'depth':7,\n",
    "    'iterations':5000,\n",
    "    'eval_metric':'MAE',\n",
    "    'random_seed':42,\n",
    "    'early_stopping_rounds':[5],\n",
    "    'learning_rate':0.1,\n",
    "    'thread_count':8,\n",
    "    'boosting_type':'Plain',\n",
    "    'bootstrap_type':'Bernoulli',\n",
    "    'colsample_bylevel':0.6\n",
    "}\n",
    "\n",
    "model_cb = CatBoostRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_ft = ['day']\n",
    "\n",
    "# cat_ft_id = list()\n",
    "# n = 0\n",
    "# for c in X_train.columns:\n",
    "#     if c in cat_ft:\n",
    "#         cat_ft_id.append(n)\n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n",
      "0:\tlearn: 2.7921344\ttest: 2.8562083\tbest: 2.8562083 (0)\ttotal: 10.6ms\tremaining: 52.8s\n",
      "200:\tlearn: 0.4915638\ttest: 0.5117891\tbest: 0.5117891 (200)\ttotal: 1.9s\tremaining: 45.5s\n",
      "400:\tlearn: 0.4474824\ttest: 0.4858574\tbest: 0.4858574 (400)\ttotal: 3.99s\tremaining: 45.7s\n",
      "600:\tlearn: 0.4193512\ttest: 0.4731370\tbest: 0.4731370 (600)\ttotal: 5.81s\tremaining: 42.5s\n",
      "800:\tlearn: 0.3973675\ttest: 0.4657925\tbest: 0.4657925 (800)\ttotal: 7.62s\tremaining: 40s\n",
      "1000:\tlearn: 0.3783311\ttest: 0.4597350\tbest: 0.4597350 (1000)\ttotal: 9.51s\tremaining: 38s\n",
      "1200:\tlearn: 0.3619541\ttest: 0.4557549\tbest: 0.4557549 (1200)\ttotal: 11.6s\tremaining: 36.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4534729825\n",
      "bestIteration = 1358\n",
      "\n",
      "Shrink model to first 1359 iterations.\n",
      "--- Fold k 2:\n",
      "0:\tlearn: 2.8202971\ttest: 2.7346086\tbest: 2.7346086 (0)\ttotal: 9.42ms\tremaining: 47.1s\n",
      "200:\tlearn: 0.4932372\ttest: 0.5076623\tbest: 0.5076623 (200)\ttotal: 2.22s\tremaining: 53s\n",
      "400:\tlearn: 0.4493619\ttest: 0.4831446\tbest: 0.4831446 (400)\ttotal: 4.16s\tremaining: 47.7s\n",
      "600:\tlearn: 0.4215830\ttest: 0.4717762\tbest: 0.4717762 (600)\ttotal: 6.53s\tremaining: 47.8s\n",
      "800:\tlearn: 0.3994664\ttest: 0.4639914\tbest: 0.4639914 (800)\ttotal: 8.36s\tremaining: 43.8s\n",
      "1000:\tlearn: 0.3799541\ttest: 0.4571336\tbest: 0.4571336 (1000)\ttotal: 10.3s\tremaining: 41.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4537693947\n",
      "bestIteration = 1146\n",
      "\n",
      "Shrink model to first 1147 iterations.\n",
      "--- Fold k 3:\n",
      "0:\tlearn: 2.8261985\ttest: 2.7814892\tbest: 2.7814892 (0)\ttotal: 10.5ms\tremaining: 52.3s\n",
      "200:\tlearn: 0.4894888\ttest: 0.5189849\tbest: 0.5189849 (200)\ttotal: 1.76s\tremaining: 42s\n",
      "400:\tlearn: 0.4459081\ttest: 0.4925640\tbest: 0.4925640 (400)\ttotal: 3.5s\tremaining: 40.2s\n",
      "600:\tlearn: 0.4176912\ttest: 0.4798814\tbest: 0.4798814 (600)\ttotal: 5.24s\tremaining: 38.3s\n",
      "800:\tlearn: 0.3955951\ttest: 0.4723237\tbest: 0.4723237 (800)\ttotal: 7s\tremaining: 36.7s\n",
      "1000:\tlearn: 0.3768159\ttest: 0.4666500\tbest: 0.4666500 (1000)\ttotal: 8.85s\tremaining: 35.3s\n",
      "1200:\tlearn: 0.3603122\ttest: 0.4620673\tbest: 0.4620673 (1200)\ttotal: 10.8s\tremaining: 34.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.460934584\n",
      "bestIteration = 1304\n",
      "\n",
      "Shrink model to first 1305 iterations.\n",
      "--- Fold k 4:\n",
      "0:\tlearn: 2.7688300\ttest: 2.9469318\tbest: 2.9469318 (0)\ttotal: 9.52ms\tremaining: 47.6s\n",
      "200:\tlearn: 0.4897386\ttest: 0.5217498\tbest: 0.5217498 (200)\ttotal: 1.76s\tremaining: 42s\n",
      "400:\tlearn: 0.4457571\ttest: 0.4939458\tbest: 0.4939458 (400)\ttotal: 3.49s\tremaining: 40s\n",
      "600:\tlearn: 0.4172631\ttest: 0.4813203\tbest: 0.4813203 (600)\ttotal: 5.23s\tremaining: 38.3s\n",
      "800:\tlearn: 0.3953420\ttest: 0.4728256\tbest: 0.4728246 (798)\ttotal: 6.96s\tremaining: 36.5s\n",
      "1000:\tlearn: 0.3771696\ttest: 0.4677581\tbest: 0.4677581 (1000)\ttotal: 8.74s\tremaining: 34.9s\n",
      "1200:\tlearn: 0.3613480\ttest: 0.4630797\tbest: 0.4630797 (1200)\ttotal: 10.5s\tremaining: 33.3s\n",
      "1400:\tlearn: 0.3469104\ttest: 0.4599875\tbest: 0.4599875 (1400)\ttotal: 12.3s\tremaining: 31.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4579387615\n",
      "bestIteration = 1526\n",
      "\n",
      "Shrink model to first 1527 iterations.\n",
      "--- Fold k 5:\n",
      "0:\tlearn: 2.8313120\ttest: 2.7096092\tbest: 2.7096092 (0)\ttotal: 8.9ms\tremaining: 44.5s\n",
      "200:\tlearn: 0.4916145\ttest: 0.5121649\tbest: 0.5121649 (200)\ttotal: 1.77s\tremaining: 42.3s\n",
      "400:\tlearn: 0.4497931\ttest: 0.4875779\tbest: 0.4875779 (400)\ttotal: 3.61s\tremaining: 41.4s\n",
      "600:\tlearn: 0.4213528\ttest: 0.4746821\tbest: 0.4746821 (600)\ttotal: 5.4s\tremaining: 39.5s\n",
      "800:\tlearn: 0.3983910\ttest: 0.4665672\tbest: 0.4665672 (800)\ttotal: 7.18s\tremaining: 37.7s\n",
      "1000:\tlearn: 0.3789619\ttest: 0.4609847\tbest: 0.4609847 (1000)\ttotal: 8.97s\tremaining: 35.8s\n",
      "1200:\tlearn: 0.3627970\ttest: 0.4568994\tbest: 0.4568894 (1197)\ttotal: 10.7s\tremaining: 34s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.4547165476\n",
      "bestIteration = 1356\n",
      "\n",
      "Shrink model to first 1357 iterations.\n",
      "IMPORTANCIA DE LAS VARIABLES:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>category_id</td>\n",
       "      <td>7.522169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std_stock_shift1</td>\n",
       "      <td>5.721651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mean_stock_shift3</td>\n",
       "      <td>5.687084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>diff_stock_lead1</td>\n",
       "      <td>5.480231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std_stock</td>\n",
       "      <td>4.794732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>std_stock_shift2</td>\n",
       "      <td>4.735298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stock</td>\n",
       "      <td>4.418439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>position</td>\n",
       "      <td>3.246536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>median_stock_shift3</td>\n",
       "      <td>2.431827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>diff_stock_lag1</td>\n",
       "      <td>2.245342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>diff_stock_lead2</td>\n",
       "      <td>2.181249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_stock_shift2</td>\n",
       "      <td>1.782716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_stock_shift1</td>\n",
       "      <td>1.725838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>diff_pos_lag1</td>\n",
       "      <td>1.702710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ratio_position</td>\n",
       "      <td>1.700906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>min_stock_shift3</td>\n",
       "      <td>1.691195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family_id</td>\n",
       "      <td>1.674935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stock_lag1</td>\n",
       "      <td>1.640435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>max_stock_shift3</td>\n",
       "      <td>1.618586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>N6</td>\n",
       "      <td>1.513329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>price</td>\n",
       "      <td>1.503586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>diff_stock_lag2</td>\n",
       "      <td>1.458898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>std_pos_shift1</td>\n",
       "      <td>1.413769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stock_lead2</td>\n",
       "      <td>1.407779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subfamily_id</td>\n",
       "      <td>1.365408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stock_lead1</td>\n",
       "      <td>1.298748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>median_stock_shift1</td>\n",
       "      <td>1.295640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max_stock_shift1</td>\n",
       "      <td>1.283122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>N3</td>\n",
       "      <td>1.242276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stock_lag2</td>\n",
       "      <td>1.203150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>N13</td>\n",
       "      <td>0.868936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>size_id</td>\n",
       "      <td>0.849674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>N10</td>\n",
       "      <td>0.847866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>diff_pos_lead1</td>\n",
       "      <td>0.720966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>N12</td>\n",
       "      <td>0.676820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>min_pos_shift3</td>\n",
       "      <td>0.666267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pos_lag1</td>\n",
       "      <td>0.633392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>diff_pos_lead2</td>\n",
       "      <td>0.587161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>N1</td>\n",
       "      <td>0.553520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>min_pos_shift2</td>\n",
       "      <td>0.541681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>std_pos_shift2</td>\n",
       "      <td>0.537075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>color_id</td>\n",
       "      <td>0.505461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mean_stock_shift2</td>\n",
       "      <td>0.470693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>std_stock_shift3</td>\n",
       "      <td>0.461824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>N7</td>\n",
       "      <td>0.456322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>N2</td>\n",
       "      <td>0.424657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>min_pos_shift1</td>\n",
       "      <td>0.407610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>max_pos_shift2</td>\n",
       "      <td>0.368888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>max_pos_shift3</td>\n",
       "      <td>0.346005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mean_pos_shift3</td>\n",
       "      <td>0.342048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>std_pos_shift3</td>\n",
       "      <td>0.334398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>median_pos_shift3</td>\n",
       "      <td>0.334340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>median_pos_shift2</td>\n",
       "      <td>0.305348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pos_lag2</td>\n",
       "      <td>0.301602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pos_lead1</td>\n",
       "      <td>0.287100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mean_pos_shift2</td>\n",
       "      <td>0.279583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pos_lead2</td>\n",
       "      <td>0.247907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>median_pos_shift1</td>\n",
       "      <td>0.239916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>max_pos_shift1</td>\n",
       "      <td>0.217716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mean_pos_shift1</td>\n",
       "      <td>0.196042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  importance\n",
       "7           category_id    7.522169\n",
       "11     std_stock_shift1    5.721651\n",
       "46    mean_stock_shift3    5.687084\n",
       "37     diff_stock_lead1    5.480231\n",
       "1             std_stock    4.794732\n",
       "18     std_stock_shift2    4.735298\n",
       "0                 stock    4.418439\n",
       "6              position    3.246536\n",
       "49  median_stock_shift3    2.431827\n",
       "39      diff_stock_lag1    2.245342\n",
       "38     diff_stock_lead2    2.181249\n",
       "20     max_stock_shift2    1.782716\n",
       "12    mean_stock_shift1    1.725838\n",
       "43        diff_pos_lag1    1.702710\n",
       "57       ratio_position    1.700906\n",
       "47     min_stock_shift3    1.691195\n",
       "2             family_id    1.674935\n",
       "9            stock_lag1    1.640435\n",
       "48     max_stock_shift3    1.618586\n",
       "62                   N6    1.513329\n",
       "8                 price    1.503586\n",
       "40      diff_stock_lag2    1.458898\n",
       "25       std_pos_shift1    1.413769\n",
       "17          stock_lead2    1.407779\n",
       "3          subfamily_id    1.365408\n",
       "10          stock_lead1    1.298748\n",
       "15  median_stock_shift1    1.295640\n",
       "14     max_stock_shift1    1.283122\n",
       "60                   N3    1.242276\n",
       "16           stock_lag2    1.203150\n",
       "..                  ...         ...\n",
       "68                  N13    0.868936\n",
       "4               size_id    0.849674\n",
       "66                  N10    0.847866\n",
       "41       diff_pos_lead1    0.720966\n",
       "67                  N12    0.676820\n",
       "52       min_pos_shift3    0.666267\n",
       "23             pos_lag1    0.633392\n",
       "42       diff_pos_lead2    0.587161\n",
       "58                   N1    0.553520\n",
       "33       min_pos_shift2    0.541681\n",
       "32       std_pos_shift2    0.537075\n",
       "5              color_id    0.505461\n",
       "22    mean_stock_shift2    0.470693\n",
       "45     std_stock_shift3    0.461824\n",
       "63                   N7    0.456322\n",
       "59                   N2    0.424657\n",
       "27       min_pos_shift1    0.407610\n",
       "34       max_pos_shift2    0.368888\n",
       "53       max_pos_shift3    0.346005\n",
       "51      mean_pos_shift3    0.342048\n",
       "50       std_pos_shift3    0.334398\n",
       "54    median_pos_shift3    0.334340\n",
       "35    median_pos_shift2    0.305348\n",
       "30             pos_lag2    0.301602\n",
       "24            pos_lead1    0.287100\n",
       "36      mean_pos_shift2    0.279583\n",
       "31            pos_lead2    0.247907\n",
       "29    median_pos_shift1    0.239916\n",
       "28       max_pos_shift1    0.217716\n",
       "26      mean_pos_shift1    0.196042\n",
       "\n",
       "[69 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    model_cb.fit(X_fit,\n",
    "                 y_fit,\n",
    "                 eval_set=[(X_val, y_val)],\n",
    "                 verbose=200,\n",
    "#                  cat_features=cat_ft_id,\n",
    "                 early_stopping_rounds=10)\n",
    "\n",
    "    ft_importances += model_cb.feature_importances_\n",
    "\n",
    "    be += np.expm1(model_cb.best_score_['validation_0']['MAE'])\n",
    "    y_preds = np.expm1(model_cb.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "pr = pd.DataFrame({'predicciones_catboost_pw': full_preds})\n",
    "pr.to_csv('../predictions/preds_catboost_pw.csv')\n",
    "\n",
    "print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "df_imp_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = X_train.fillna(-1)#.sample(frac=0.1)\n",
    "X_fit, X_val, y_fit, y_val = train_test_split(X_train_sample,\n",
    "                                              y_train.iloc[X_train_sample.index.values],\n",
    "                                              test_size=0.25,\n",
    "                                              random_state=42)\n",
    "\n",
    "y_val = np.log1p(y_val)\n",
    "y_fit = np.log1p(y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=0.0,\n",
    "                           patience=3,\n",
    "                           verbose=1,\n",
    "                           mode='min',\n",
    "                           restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(512, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.add(Masking(mask_value=-1))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=create_baseline,\n",
    "                           epochs=100,\n",
    "                           batch_size=1024,\n",
    "                           verbose=1,\n",
    "                           callbacks=callbacks,\n",
    "                           validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53986 samples, validate on 12954 samples\n",
      "Epoch 1/100\n",
      "53986/53986 [==============================] - 3s 57us/step - loss: 71.5701 - val_loss: 40.5570\n",
      "Epoch 2/100\n",
      "53986/53986 [==============================] - 2s 41us/step - loss: 56.9466 - val_loss: 39.2343\n",
      "Epoch 3/100\n",
      "53986/53986 [==============================] - 2s 41us/step - loss: 54.9822 - val_loss: 39.2244\n",
      "Epoch 4/100\n",
      "53986/53986 [==============================] - 2s 42us/step - loss: 53.6224 - val_loss: 38.5947\n",
      "Epoch 5/100\n",
      "53986/53986 [==============================] - 2s 42us/step - loss: 51.8336 - val_loss: 35.3132\n",
      "Epoch 6/100\n",
      "53986/53986 [==============================] - 2s 41us/step - loss: 50.3344 - val_loss: 35.2626\n",
      "Epoch 7/100\n",
      "53986/53986 [==============================] - 2s 42us/step - loss: 49.2566 - val_loss: 33.7970\n",
      "Epoch 8/100\n",
      "53986/53986 [==============================] - 2s 42us/step - loss: 49.0929 - val_loss: 35.3010\n",
      "Epoch 9/100\n",
      "53986/53986 [==============================] - 2s 43us/step - loss: 47.8999 - val_loss: 34.8923\n",
      "Epoch 10/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 47.1209 - val_loss: 33.6530\n",
      "Epoch 11/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 46.7636 - val_loss: 33.3094\n",
      "Epoch 12/100\n",
      "53986/53986 [==============================] - 3s 48us/step - loss: 46.4143 - val_loss: 32.3359\n",
      "Epoch 13/100\n",
      "53986/53986 [==============================] - 2s 46us/step - loss: 45.3639 - val_loss: 32.8050\n",
      "Epoch 14/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 45.1525 - val_loss: 32.9323\n",
      "Epoch 15/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 44.2993 - val_loss: 31.9422\n",
      "Epoch 16/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 44.0998 - val_loss: 32.4332\n",
      "Epoch 17/100\n",
      "53986/53986 [==============================] - 2s 44us/step - loss: 44.2286 - val_loss: 32.4143\n",
      "Epoch 18/100\n",
      "53986/53986 [==============================] - 3s 49us/step - loss: 43.1077 - val_loss: 32.8448\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = estimator.fit(X_fit, y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8892/8892 [==============================] - 0s 42us/step\n"
     ]
    }
   ],
   "source": [
    "keras_preds = estimator.predict(X_test.fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6985578e+22, 6.4428597e+23, 8.6390270e+11, 8.6514801e+01,\n",
       "       2.7918719e+26,           inf,           inf, 8.3036050e-02,\n",
       "       1.2666060e+06, 8.2322948e+34, 4.8008733e+00, 4.0634163e+09,\n",
       "       1.2145674e+02, 1.6532171e+00,           inf, 2.4927830e+32,\n",
       "       2.1460220e+25, 1.0394682e+07, 2.5452344e+05, 3.0771423e+24],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(keras_preds)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "ridge = Ridge(alpha=100,\n",
    "              fit_intercept=True,\n",
    "              normalize=False,\n",
    "              copy_X=True,\n",
    "              max_iter=1e6,\n",
    "              tol=0.01,\n",
    "              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold k 1\n",
      "\n",
      "Score en el test: 64.88086937583938 ventas\n",
      "Fold k 2\n",
      "\n",
      "Score en el test: 54.13480765738701 ventas\n",
      "Fold k 3\n",
      "\n",
      "Score en el test: 57.697222867256 ventas\n",
      "Fold k 4\n",
      "\n",
      "Score en el test: 95.66856823488475 ventas\n",
      "Fold k 5\n",
      "\n",
      "Score en el test: 54.505076034070875 ventas\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('Fold k {}\\n'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    X_fit = X_fit.fillna(-1)\n",
    "    X_val = X_val.fillna(-1)\n",
    "    \n",
    "#     y_val = np.log1p(y_val)\n",
    "#     y_fit = np.log1p(y_fit)\n",
    "    \n",
    "    ridge.fit(X_fit, y_fit)\n",
    "    \n",
    "    print('Score en el test:',mean_absolute_error(ridge.predict(X_val), y_val),'ventas')\n",
    "#     print('Score en el test:',mean_absolute_error(np.expm1(lasso.predict(X_test.fillna(-1))), y_test),'ventas')\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    \n",
    "# print('\\n\\nBEST SCORE MEAN:', be / k,'SALES :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score en el test: 14.756823797072453 ventas\n",
      "Score en el test: 14.100715922865659 ventas\n",
      "Score en el test: 12.151307647028101 ventas\n",
      "Score en el test: 51.86876752206717 ventas\n",
      "Score en el test: 71.48256121213558 ventas\n",
      "Score en el test: 71.92217457062922 ventas\n",
      "Score en el test: 68.28141522284636 ventas\n",
      "Score en el test: 70.27419173579888 ventas\n",
      "Score en el test: 68.17364411398036 ventas\n",
      "Score en el test: 68.03255886397835 ventas\n",
      "Score en el test: 67.67764600238846 ventas\n",
      "Score en el test: 67.92744267608478 ventas\n",
      "Score en el test: 60.29241413900714 ventas\n",
      "Score en el test: 73.54090753222067 ventas\n",
      "Score en el test: 98.75496060857435 ventas\n",
      "Score en el test: 101.1358736415784 ventas\n",
      "Score en el test: 94.34493406037016 ventas\n",
      "Score en el test: 89.109853582185 ventas\n",
      "Score en el test: 94.87292021432982 ventas\n",
      "Score en el test: 101.50598193500386 ventas\n",
      "Score en el test: 83.5619960969 ventas\n",
      "Score en el test: 82.39001244804034 ventas\n",
      "Score en el test: 79.99393026544735 ventas\n",
      "Score en el test: 69.05517201811276 ventas\n",
      "Score en el test: 75.39925338460172 ventas\n",
      "Score en el test: 74.36319513002407 ventas\n",
      "Score en el test: 67.22396383096311 ventas\n",
      "Score en el test: 67.85436268596388 ventas\n",
      "Score en el test: 74.61815992422738 ventas\n",
      "Score en el test: 68.06128670898939 ventas\n",
      "Score en el test: 72.33887535656895 ventas\n",
      "Score en el test: 70.29216019183501 ventas\n",
      "Score en el test: 81.22020530495422 ventas\n",
      "Score en el test: 61.87964993881166 ventas\n",
      "Score en el test: 67.80441667877402 ventas\n",
      "Score en el test: 72.19305653389645 ventas\n",
      "Score en el test: 58.85607550345796 ventas\n",
      "Score en el test: 64.08785036422316 ventas\n",
      "Score en el test: 70.77121186590314 ventas\n",
      "Score en el test: 72.21325343027388 ventas\n",
      "Score en el test: 76.35200226669929 ventas\n",
      "Score en el test: 64.68623982362757 ventas\n",
      "Score en el test: 66.504362465678 ventas\n",
      "Score en el test: 53.27655276424894 ventas\n",
      "Score en el test: 64.82435387763033 ventas\n",
      "Score en el test: 63.339900427294054 ventas\n",
      "Score en el test: 66.9712207390014 ventas\n",
      "Score en el test: 71.03898290086933 ventas\n",
      "Score en el test: 73.56998264783722 ventas\n",
      "Score en el test: 60.49236753667905 ventas\n",
      "Score en el test: 60.35686257938372 ventas\n",
      "Score en el test: 63.923448725303864 ventas\n",
      "Score en el test: 58.06525113389149 ventas\n",
      "Score en el test: 64.2718073342924 ventas\n",
      "Score en el test: 61.613301526332485 ventas\n",
      "Score en el test: 63.80576215676884 ventas\n",
      "Score en el test: 61.064446709285484 ventas\n",
      "Score en el test: 62.21291398207712 ventas\n",
      "Score en el test: 58.2944098984143 ventas\n",
      "Score en el test: 62.351817467363965 ventas\n",
      "Score en el test: 59.14517604544217 ventas\n",
      "Score en el test: 62.42236745944205 ventas\n",
      "Score en el test: 57.73512971036944 ventas\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    X_fit = X_fit.fillna(-1)\n",
    "    X_val = X_val.fillna(-1)\n",
    "    \n",
    "#     y_val = np.log1p(y_val)\n",
    "#     y_fit = np.log1p(y_fit)\n",
    "    \n",
    "    \n",
    "    ridge.fit(X_fit,\n",
    "                  y_fit,\n",
    "#                   eval_set=[(X_val, y_val)],\n",
    "#                   verbose=1000,\n",
    "#                   early_stopping_rounds=20\n",
    "             )\n",
    "    \n",
    "    print('Score en el test:',mean_absolute_error(ridge.predict(X_val), y_val),'ventas')\n",
    "\n",
    "#     be += np.expm1(lgb_model.best_score_['valid_0']['l1'])\n",
    "#     be += lgb_model.best_score_['valid_0']['l1']\n",
    "    \n",
    "#     print('Score en el test:',mean_absolute_error(lgb_model.predict(X_test), y_test),'ventas')\n",
    "#     print('Score en el test:',mean_absolute_error(np.expm1(lgb_model.predict(X_test)), y_test),'ventas')\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
