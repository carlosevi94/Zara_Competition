{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from eli5 import show_weights, show_prediction\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/final_train.csv')\n",
    "test = pd.read_csv('../data/final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_number</th>\n",
       "      <th>product_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>position_max</th>\n",
       "      <th>...</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>310130</td>\n",
       "      <td>1726</td>\n",
       "      <td>1383</td>\n",
       "      <td>34.811328</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>36187</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1178388</td>\n",
       "      <td>592</td>\n",
       "      <td>60</td>\n",
       "      <td>2.160247</td>\n",
       "      <td>0.049198</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4787</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>66956</td>\n",
       "      <td>64</td>\n",
       "      <td>1323</td>\n",
       "      <td>752</td>\n",
       "      <td>115</td>\n",
       "      <td>64</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1561460</td>\n",
       "      <td>1625</td>\n",
       "      <td>2373</td>\n",
       "      <td>55.438769</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9866</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>49495</td>\n",
       "      <td>64</td>\n",
       "      <td>7089</td>\n",
       "      <td>2551</td>\n",
       "      <td>401</td>\n",
       "      <td>86</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1874414</td>\n",
       "      <td>1135</td>\n",
       "      <td>1686</td>\n",
       "      <td>20.463906</td>\n",
       "      <td>0.110784</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5942</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>31410</td>\n",
       "      <td>64</td>\n",
       "      <td>1683</td>\n",
       "      <td>466</td>\n",
       "      <td>74</td>\n",
       "      <td>64</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2436420</td>\n",
       "      <td>779</td>\n",
       "      <td>245</td>\n",
       "      <td>23.377339</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1880</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>49495</td>\n",
       "      <td>64</td>\n",
       "      <td>175</td>\n",
       "      <td>98</td>\n",
       "      <td>15</td>\n",
       "      <td>137</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_number  product_id  block_id  stock  std_stock  family_id  \\\n",
       "0            0      310130      1726   1383  34.811328   0.007130   \n",
       "1            0     1178388       592     60   2.160247   0.049198   \n",
       "2            0     1561460      1625   2373  55.438769   0.123964   \n",
       "3            0     1874414      1135   1686  20.463906   0.110784   \n",
       "4            0     2436420       779    245  23.377339   0.025903   \n",
       "\n",
       "   subfamily_id  size_id  color_id  position_max  ...    N3  N5  N6     N7  \\\n",
       "0      0.000598        7         1          80.0  ...   250  64  61  36187   \n",
       "1      0.012761        4         1          19.0  ...  4787  64  64  66956   \n",
       "2      0.023599        5         1          38.0  ...  9866  64  64  49495   \n",
       "3      0.016021        6         1         190.0  ...  5942  64  64  31410   \n",
       "4      0.004497        5         1           NaN  ...  1880  64  64  49495   \n",
       "\n",
       "   N8    N9   N10  N11  N12   N13  \n",
       "0  64    64    61    9   95    56  \n",
       "1  64  1323   752  115   64  1749  \n",
       "2  64  7089  2551  401   86  2261  \n",
       "3  64  1683   466   74   64  1827  \n",
       "4  64   175    98   15  137   658  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_number</th>\n",
       "      <th>product_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>position_max</th>\n",
       "      <th>...</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>151926</td>\n",
       "      <td>1969</td>\n",
       "      <td>636</td>\n",
       "      <td>33.103206</td>\n",
       "      <td>0.131242</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2198</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8113</td>\n",
       "      <td>7</td>\n",
       "      <td>1169</td>\n",
       "      <td>413</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>213413</td>\n",
       "      <td>1648</td>\n",
       "      <td>1190</td>\n",
       "      <td>36.225788</td>\n",
       "      <td>0.034750</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>...</td>\n",
       "      <td>196</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5145</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>310130</td>\n",
       "      <td>1726</td>\n",
       "      <td>442</td>\n",
       "      <td>52.809180</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5145</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>455200</td>\n",
       "      <td>1400</td>\n",
       "      <td>86</td>\n",
       "      <td>6.831301</td>\n",
       "      <td>0.043185</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>287</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6391</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "      <td>571044</td>\n",
       "      <td>1098</td>\n",
       "      <td>416</td>\n",
       "      <td>42.178063</td>\n",
       "      <td>0.103014</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>205.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1036</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1673</td>\n",
       "      <td>7</td>\n",
       "      <td>441</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_number  product_id  block_id  stock  std_stock  family_id  \\\n",
       "0           71      151926      1969    636  33.103206   0.131242   \n",
       "1           71      213413      1648   1190  36.225788   0.034750   \n",
       "2           71      310130      1726    442  52.809180   0.008210   \n",
       "3           71      455200      1400     86   6.831301   0.043185   \n",
       "4           71      571044      1098    416  42.178063   0.103014   \n",
       "\n",
       "   subfamily_id  size_id  color_id  position_max  ...    N3  N5  N6    N7  N8  \\\n",
       "0      0.035875        5         1          22.0  ...  2198   7   7  8113   7   \n",
       "1      0.003149        7         1         139.0  ...   196   7   7  5145   7   \n",
       "2      0.000562        7         1          46.0  ...    35   7   7  5145   7   \n",
       "3      0.007647        3         1          53.0  ...   287   7   7  6391   7   \n",
       "4      0.023392        4         2         205.0  ...  1036   7   7  1673   7   \n",
       "\n",
       "     N9  N10  N11  N12  N13  \n",
       "0  1169  413   59    7  615  \n",
       "1    42   28    4    7   80  \n",
       "2     7    7    1    7   10  \n",
       "3    63   49    7    7   75  \n",
       "4   441   98   14    7  145  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['sales', 'date_number', 'product_id', 'block_id',\n",
    "             'position_max', 'position_min', 'std_position', 'ratio_std_pos', 'diff_position'\n",
    "            ]\n",
    "\n",
    "X_train = train.loc[:,[c for c in train.columns if c not in drop_cols]]\n",
    "y_train = train[['sales']]\n",
    "X_test = test.loc[:,[c for c in train.columns if c not in drop_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarización de las variables para modelos lineales y redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ss = ['stock', 'std_stock', 'size_id',\n",
    "       'color_id', 'category_id', 'price', 'stock_lag1',\n",
    "       'stock_lead1', 'std_stock_shift1', 'mean_stock_shift1',\n",
    "       'min_stock_shift1', 'max_stock_shift1', 'median_stock_shift1',\n",
    "       'kurtosis_stock_shift1', 'stock_lag2', 'stock_lead2',\n",
    "       'std_stock_shift2', 'min_stock_shift2', 'max_stock_shift2',\n",
    "       'median_stock_shift2', 'mean_stock_shift2', 'kurtosis_stock_shift2',\n",
    "       'diff_stock_lead1', 'diff_stock_lead2', 'diff_stock_lag1',\n",
    "       'diff_stock_lag2', 'std_stock_shift3', 'mean_stock_shift3',\n",
    "       'min_stock_shift3', 'max_stock_shift3', 'median_stock_shift3',\n",
    "       'kurtosis_stock_shift3', 'size_p_color', 'size_d_color',\n",
    "       'ratio_kurtosis_stock_shift3', 'ratio_median_stock_shift3',\n",
    "       'ratio_mean_stock_shift3', 'ratio_max_stock_shift3',\n",
    "       'ratio_min_stock_shift3', 'ratio_kurtosis_stock_shift2',\n",
    "       'ratio_median_stock_shift2', 'ratio_mean_stock_shift2',\n",
    "       'ratio_max_stock_shift2', 'ratio_min_stock_shift2',\n",
    "       'ratio_kurtosis_stock_shift1', 'ratio_median_stock_shift1',\n",
    "       'ratio_mean_stock_shift1', 'ratio_max_stock_shift1',\n",
    "       'ratio_min_stock_shift1', 'ratio_std_stock', 'ratio_std_shift1',\n",
    "       'ratio_std_shift2', 'N1', 'N2', 'N3', 'N5', 'N6', 'N7', 'N8', 'N9',\n",
    "       'N10', 'N11', 'N12', 'N13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/errodringer/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train[cols_ss])\n",
    "X_train[cols_ss] = ss.transform(X_train[cols_ss])\n",
    "X_test[cols_ss] = ss.transform(X_test[cols_ss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>std_stock</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subfamily_id</th>\n",
       "      <th>size_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>price</th>\n",
       "      <th>day</th>\n",
       "      <th>weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>N3</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.109097</td>\n",
       "      <td>0.282014</td>\n",
       "      <td>0.131242</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>0.263422</td>\n",
       "      <td>-0.394119</td>\n",
       "      <td>-0.146276</td>\n",
       "      <td>0.029460</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296182</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-1.929805</td>\n",
       "      <td>-1.384708</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.046195</td>\n",
       "      <td>0.043777</td>\n",
       "      <td>-1.579103</td>\n",
       "      <td>0.045027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.218999</td>\n",
       "      <td>0.378338</td>\n",
       "      <td>0.034750</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>1.103052</td>\n",
       "      <td>-0.394119</td>\n",
       "      <td>-0.146276</td>\n",
       "      <td>-0.329163</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.982882</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-1.929805</td>\n",
       "      <td>-1.523080</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-0.698026</td>\n",
       "      <td>-0.650395</td>\n",
       "      <td>-0.651002</td>\n",
       "      <td>-1.579103</td>\n",
       "      <td>-0.667512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.223990</td>\n",
       "      <td>0.889899</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>1.103052</td>\n",
       "      <td>-0.394119</td>\n",
       "      <td>-0.726088</td>\n",
       "      <td>-0.747557</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.038107</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-1.929805</td>\n",
       "      <td>-1.523080</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-0.722521</td>\n",
       "      <td>-0.688390</td>\n",
       "      <td>-0.688899</td>\n",
       "      <td>-1.579103</td>\n",
       "      <td>-0.760742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.434825</td>\n",
       "      <td>-0.528417</td>\n",
       "      <td>0.043185</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>-0.576207</td>\n",
       "      <td>-0.394119</td>\n",
       "      <td>-0.146276</td>\n",
       "      <td>0.268542</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.951669</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-1.929805</td>\n",
       "      <td>-1.464989</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-0.683329</td>\n",
       "      <td>-0.612399</td>\n",
       "      <td>-0.613105</td>\n",
       "      <td>-1.579103</td>\n",
       "      <td>-0.674171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.239388</td>\n",
       "      <td>0.561953</td>\n",
       "      <td>0.103014</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>-0.156392</td>\n",
       "      <td>0.743460</td>\n",
       "      <td>-0.146276</td>\n",
       "      <td>-0.568246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.694756</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-1.929805</td>\n",
       "      <td>-1.684949</td>\n",
       "      <td>-3.726844</td>\n",
       "      <td>-0.418788</td>\n",
       "      <td>-0.523742</td>\n",
       "      <td>-0.524678</td>\n",
       "      <td>-1.579103</td>\n",
       "      <td>-0.580942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stock  std_stock  family_id  subfamily_id   size_id  color_id  \\\n",
       "0 -0.109097   0.282014   0.131242      0.035875  0.263422 -0.394119   \n",
       "1  0.218999   0.378338   0.034750      0.003149  1.103052 -0.394119   \n",
       "2 -0.223990   0.889899   0.008210      0.000562  1.103052 -0.394119   \n",
       "3 -0.434825  -0.528417   0.043185      0.007647 -0.576207 -0.394119   \n",
       "4 -0.239388   0.561953   0.103014      0.023392 -0.156392  0.743460   \n",
       "\n",
       "   category_id     price  day  weekend  ...        N3        N5        N6  \\\n",
       "0    -0.146276  0.029460    3        0  ... -0.296182 -3.726844 -1.929805   \n",
       "1    -0.146276 -0.329163    3        0  ... -0.982882 -3.726844 -1.929805   \n",
       "2    -0.726088 -0.747557    3        0  ... -1.038107 -3.726844 -1.929805   \n",
       "3    -0.146276  0.268542    3        0  ... -0.951669 -3.726844 -1.929805   \n",
       "4    -0.146276 -0.568246    3        0  ... -0.694756 -3.726844 -1.929805   \n",
       "\n",
       "         N7        N8        N9       N10       N11       N12       N13  \n",
       "0 -1.384708 -3.726844  0.090700  0.046195  0.043777 -1.579103  0.045027  \n",
       "1 -1.523080 -3.726844 -0.698026 -0.650395 -0.651002 -1.579103 -0.667512  \n",
       "2 -1.523080 -3.726844 -0.722521 -0.688390 -0.688899 -1.579103 -0.760742  \n",
       "3 -1.464989 -3.726844 -0.683329 -0.612399 -0.613105 -1.579103 -0.674171  \n",
       "4 -1.684949 -3.726844 -0.418788 -0.523742 -0.524678 -1.579103 -0.580942  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train.index\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = X_train.corr()\n",
    "\n",
    "# # plot the heatmap\n",
    "# sns.heatmap(corr, \n",
    "#         xticklabels=corr.columns,\n",
    "#         yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sample = X_train.fillna(-1).sample(frac=0.1)\n",
    "# X_fit, X_val, y_fit, y_val = train_test_split(X_train_sample,\n",
    "#                                               y_train.iloc[X_train_sample.index.values],\n",
    "#                                               test_size=0.25,\n",
    "#                                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'n_estimators': 500,\n",
    "#     'criterion': 'entropy',\n",
    "#     'max_depth': 10,\n",
    "#     'random_state': 42,\n",
    "#     'n_jobs': 8,\n",
    "#     'verbose': 0,\n",
    "#     'min_samples_leaf': 2,\n",
    "    \n",
    "# }\n",
    "\n",
    "# rf = RandomForestClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_refit = rf.fit(X_fit, y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm = PermutationImportance(rf_refit).fit(X_val, y_val)\n",
    "# show_weights(perm, feature_names=X_val.columns.tolist(), top=X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lgbm'\n",
    "\n",
    "params = {'max_depth':7,\n",
    "          'metric':'mae',\n",
    "          'max_delta_step': 0.2,\n",
    "          'n_estimators':50000,\n",
    "          'learning_rate':0.1,\n",
    "          'colsample_bytree':0.6,\n",
    "          'objective':'regression',\n",
    "          'n_jobs':8,\n",
    "          'seed':42,\n",
    "          'lambda_l1':0,\n",
    "          'lambda_l2':0,\n",
    "#           'max_bin': 14,\n",
    "#           'bagging_fraction':0.8,\n",
    "         }\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.4232\n",
      "[2000]\tvalid_0's l1: 0.416702\n",
      "[3000]\tvalid_0's l1: 0.414104\n",
      "[4000]\tvalid_0's l1: 0.412461\n",
      "Early stopping, best iteration is:\n",
      "[4355]\tvalid_0's l1: 0.412195\n",
      "--- Fold k 2:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.420548\n",
      "[2000]\tvalid_0's l1: 0.414022\n",
      "[3000]\tvalid_0's l1: 0.411459\n",
      "Early stopping, best iteration is:\n",
      "[3240]\tvalid_0's l1: 0.411022\n",
      "--- Fold k 3:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.423485\n",
      "[2000]\tvalid_0's l1: 0.416693\n",
      "[3000]\tvalid_0's l1: 0.414091\n",
      "[4000]\tvalid_0's l1: 0.412704\n",
      "Early stopping, best iteration is:\n",
      "[4046]\tvalid_0's l1: 0.412645\n",
      "--- Fold k 4:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.423614\n",
      "[2000]\tvalid_0's l1: 0.416598\n",
      "[3000]\tvalid_0's l1: 0.413564\n",
      "Early stopping, best iteration is:\n",
      "[3653]\tvalid_0's l1: 0.412544\n",
      "--- Fold k 5:\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's l1: 0.422262\n",
      "[2000]\tvalid_0's l1: 0.415192\n",
      "[3000]\tvalid_0's l1: 0.412498\n",
      "Early stopping, best iteration is:\n",
      "[3589]\tvalid_0's l1: 0.411573\n",
      "IMPORTANCIA DE LAS VARIABLES:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>diff_stock_lead1</td>\n",
       "      <td>5071.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>diff_stock_lead2</td>\n",
       "      <td>4436.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std_stock</td>\n",
       "      <td>4269.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>diff_stock_lag1</td>\n",
       "      <td>3873.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>diff_stock_lag2</td>\n",
       "      <td>3849.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kurtosis_stock_shift2</td>\n",
       "      <td>3783.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ratio_std_shift2</td>\n",
       "      <td>3554.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ratio_std_shift1</td>\n",
       "      <td>3446.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>N12</td>\n",
       "      <td>3314.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>std_stock_shift2</td>\n",
       "      <td>3203.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_stock_shift1</td>\n",
       "      <td>3140.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>N9</td>\n",
       "      <td>3027.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subfamily_id</td>\n",
       "      <td>2951.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>category_id</td>\n",
       "      <td>2763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>kurtosis_stock_shift3</td>\n",
       "      <td>2759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>price</td>\n",
       "      <td>2578.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>N6</td>\n",
       "      <td>2502.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stock_lead2</td>\n",
       "      <td>2482.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>N1</td>\n",
       "      <td>2478.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>N10</td>\n",
       "      <td>2471.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stock_lag2</td>\n",
       "      <td>2447.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>N3</td>\n",
       "      <td>2399.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>min_stock_shift3</td>\n",
       "      <td>2300.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>N13</td>\n",
       "      <td>2257.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family_id</td>\n",
       "      <td>2174.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ratio_kurtosis_stock_shift2</td>\n",
       "      <td>2165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>N5</td>\n",
       "      <td>1985.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>N11</td>\n",
       "      <td>1914.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stock_lead1</td>\n",
       "      <td>1767.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ratio_std_stock</td>\n",
       "      <td>1754.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>max_stock_shift2</td>\n",
       "      <td>1121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>N2</td>\n",
       "      <td>974.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>size_id</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>min_stock_shift1</td>\n",
       "      <td>935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ratio_min_stock_shift3</td>\n",
       "      <td>917.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>median_stock_shift3</td>\n",
       "      <td>913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stock</td>\n",
       "      <td>894.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>N8</td>\n",
       "      <td>856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max_stock_shift1</td>\n",
       "      <td>740.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mean_stock_shift1</td>\n",
       "      <td>692.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mean_stock_shift3</td>\n",
       "      <td>674.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mean_stock_shift2</td>\n",
       "      <td>657.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>median_stock_shift2</td>\n",
       "      <td>650.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>median_stock_shift1</td>\n",
       "      <td>586.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ratio_min_stock_shift2</td>\n",
       "      <td>506.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>max_stock_shift3</td>\n",
       "      <td>421.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ratio_median_stock_shift3</td>\n",
       "      <td>400.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ratio_min_stock_shift1</td>\n",
       "      <td>369.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>color_id</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ratio_mean_stock_shift2</td>\n",
       "      <td>288.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ratio_max_stock_shift1</td>\n",
       "      <td>281.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ratio_median_stock_shift2</td>\n",
       "      <td>264.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ratio_mean_stock_shift3</td>\n",
       "      <td>264.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ratio_mean_stock_shift1</td>\n",
       "      <td>236.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ratio_median_stock_shift1</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ratio_max_stock_shift3</td>\n",
       "      <td>190.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weekend</td>\n",
       "      <td>111.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ratio_max_stock_shift2</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kurtosis_stock_shift1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ratio_kurtosis_stock_shift1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  importance\n",
       "26             diff_stock_lead1      5071.4\n",
       "27             diff_stock_lead2      4436.6\n",
       "1                     std_stock      4269.6\n",
       "28              diff_stock_lag1      3873.4\n",
       "29              diff_stock_lag2      3849.2\n",
       "25        kurtosis_stock_shift2      3783.8\n",
       "55             ratio_std_shift2      3554.2\n",
       "54             ratio_std_shift1      3446.4\n",
       "66                          N12      3314.4\n",
       "20             std_stock_shift2      3203.8\n",
       "12             std_stock_shift1      3140.8\n",
       "63                           N9      3027.8\n",
       "3                  subfamily_id      2951.6\n",
       "6                   category_id      2763.0\n",
       "35        kurtosis_stock_shift3      2759.0\n",
       "7                         price      2578.8\n",
       "60                           N6      2502.2\n",
       "19                  stock_lead2      2482.6\n",
       "56                           N1      2478.4\n",
       "64                          N10      2471.8\n",
       "18                   stock_lag2      2447.2\n",
       "58                           N3      2399.4\n",
       "32             min_stock_shift3      2300.6\n",
       "67                          N13      2257.8\n",
       "2                     family_id      2174.2\n",
       "43  ratio_kurtosis_stock_shift2      2165.0\n",
       "59                           N5      1985.2\n",
       "65                          N11      1914.8\n",
       "11                  stock_lead1      1767.4\n",
       "53              ratio_std_stock      1754.2\n",
       "..                          ...         ...\n",
       "22             max_stock_shift2      1121.0\n",
       "57                           N2       974.8\n",
       "4                       size_id       973.0\n",
       "14             min_stock_shift1       935.0\n",
       "42       ratio_min_stock_shift3       917.8\n",
       "34          median_stock_shift3       913.0\n",
       "0                         stock       894.4\n",
       "62                           N8       856.0\n",
       "15             max_stock_shift1       740.4\n",
       "13            mean_stock_shift1       692.2\n",
       "31            mean_stock_shift3       674.4\n",
       "24            mean_stock_shift2       657.4\n",
       "23          median_stock_shift2       650.2\n",
       "16          median_stock_shift1       586.6\n",
       "47       ratio_min_stock_shift2       506.6\n",
       "33             max_stock_shift3       421.4\n",
       "39    ratio_median_stock_shift3       400.8\n",
       "52       ratio_min_stock_shift1       369.2\n",
       "5                      color_id       316.0\n",
       "45      ratio_mean_stock_shift2       288.6\n",
       "51       ratio_max_stock_shift1       281.2\n",
       "44    ratio_median_stock_shift2       264.8\n",
       "40      ratio_mean_stock_shift3       264.4\n",
       "50      ratio_mean_stock_shift1       236.6\n",
       "49    ratio_median_stock_shift1       229.0\n",
       "41       ratio_max_stock_shift3       190.8\n",
       "9                       weekend       111.2\n",
       "46       ratio_max_stock_shift2        65.4\n",
       "17        kurtosis_stock_shift1         0.0\n",
       "48  ratio_kurtosis_stock_shift1         0.0\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    lgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=1000,\n",
    "                  early_stopping_rounds=50)\n",
    "\n",
    "    ft_importances += lgb_model.feature_importances_\n",
    "\n",
    "    be += np.expm1(lgb_model.best_score_['valid_0']['l1'])\n",
    "    y_preds = np.expm1(lgb_model.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "pr = pd.DataFrame({'predicciones_lightgbm': full_preds})\n",
    "pr.to_csv('../predictions/preds_lightgbm.csv')\n",
    "\n",
    "print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "df_imp_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp = df_imp_sort.feature.values.tolist()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 7,\n",
    "          'metric':'mae',\n",
    "          'n_estimators': 5000,\n",
    "          'eta': 0.1,\n",
    "          'colsample_bytree':0.6,\n",
    "          'nthread':8,\n",
    "          'seed':42,\n",
    "          'objective':'reg:linear',\n",
    "         }\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n",
      "[0]\tvalidation_0-mae:1.32824\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.437427\n",
      "[200]\tvalidation_0-mae:0.428205\n",
      "[300]\tvalidation_0-mae:0.423197\n",
      "[400]\tvalidation_0-mae:0.420763\n",
      "Stopping. Best iteration:\n",
      "[456]\tvalidation_0-mae:0.419644\n",
      "\n",
      "--- Fold k 2:\n",
      "[0]\tvalidation_0-mae:1.32045\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.434285\n",
      "[200]\tvalidation_0-mae:0.426037\n",
      "[300]\tvalidation_0-mae:0.421397\n",
      "[400]\tvalidation_0-mae:0.418554\n",
      "[500]\tvalidation_0-mae:0.416463\n",
      "[600]\tvalidation_0-mae:0.415129\n",
      "[700]\tvalidation_0-mae:0.414019\n",
      "Stopping. Best iteration:\n",
      "[724]\tvalidation_0-mae:0.413783\n",
      "\n",
      "--- Fold k 3:\n",
      "[0]\tvalidation_0-mae:1.32106\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.438113\n",
      "[200]\tvalidation_0-mae:0.42846\n",
      "[300]\tvalidation_0-mae:0.424544\n",
      "[400]\tvalidation_0-mae:0.421992\n",
      "[500]\tvalidation_0-mae:0.419894\n",
      "[600]\tvalidation_0-mae:0.418278\n",
      "[700]\tvalidation_0-mae:0.417236\n",
      "Stopping. Best iteration:\n",
      "[721]\tvalidation_0-mae:0.417002\n",
      "\n",
      "--- Fold k 4:\n",
      "[0]\tvalidation_0-mae:1.33097\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.438119\n",
      "[200]\tvalidation_0-mae:0.428533\n",
      "[300]\tvalidation_0-mae:0.424192\n",
      "[400]\tvalidation_0-mae:0.421543\n",
      "[500]\tvalidation_0-mae:0.419789\n",
      "[600]\tvalidation_0-mae:0.418464\n",
      "[700]\tvalidation_0-mae:0.417385\n",
      "Stopping. Best iteration:\n",
      "[733]\tvalidation_0-mae:0.417106\n",
      "\n",
      "--- Fold k 5:\n",
      "[0]\tvalidation_0-mae:1.31554\n",
      "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
      "[100]\tvalidation_0-mae:0.436188\n",
      "[200]\tvalidation_0-mae:0.4272\n",
      "[300]\tvalidation_0-mae:0.422939\n",
      "[400]\tvalidation_0-mae:0.42046\n",
      "[500]\tvalidation_0-mae:0.418374\n",
      "[600]\tvalidation_0-mae:0.416967\n",
      "[700]\tvalidation_0-mae:0.415872\n",
      "[800]\tvalidation_0-mae:0.415015\n",
      "Stopping. Best iteration:\n",
      "[876]\tvalidation_0-mae:0.414515\n",
      "\n",
      "IMPORTANCIA DE LAS VARIABLES:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std_stock</td>\n",
       "      <td>0.052005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>diff_stock_lead1</td>\n",
       "      <td>0.043378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kurtosis_stock_shift2</td>\n",
       "      <td>0.038489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>diff_stock_lead2</td>\n",
       "      <td>0.036836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stock</td>\n",
       "      <td>0.033815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>diff_stock_lag2</td>\n",
       "      <td>0.032375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ratio_std_shift2</td>\n",
       "      <td>0.032149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ratio_std_shift1</td>\n",
       "      <td>0.030850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>kurtosis_stock_shift3</td>\n",
       "      <td>0.030336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>diff_stock_lag1</td>\n",
       "      <td>0.030156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_stock_shift1</td>\n",
       "      <td>0.028046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>std_stock_shift2</td>\n",
       "      <td>0.027685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subfamily_id</td>\n",
       "      <td>0.025130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family_id</td>\n",
       "      <td>0.023307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>N9</td>\n",
       "      <td>0.022973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>N12</td>\n",
       "      <td>0.022543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>price</td>\n",
       "      <td>0.022541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>category_id</td>\n",
       "      <td>0.021884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stock_lag2</td>\n",
       "      <td>0.020869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stock_lead2</td>\n",
       "      <td>0.020412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stock_lag1</td>\n",
       "      <td>0.019994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>N3</td>\n",
       "      <td>0.019281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>N1</td>\n",
       "      <td>0.018783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>N6</td>\n",
       "      <td>0.018492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stock_lead1</td>\n",
       "      <td>0.018257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>N10</td>\n",
       "      <td>0.017548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>min_stock_shift3</td>\n",
       "      <td>0.017470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ratio_kurtosis_stock_shift2</td>\n",
       "      <td>0.015991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>N13</td>\n",
       "      <td>0.015708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>N5</td>\n",
       "      <td>0.015287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>size_d_color</td>\n",
       "      <td>0.009318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>N2</td>\n",
       "      <td>0.008444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>N7</td>\n",
       "      <td>0.008340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>min_stock_shift1</td>\n",
       "      <td>0.008152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mean_stock_shift1</td>\n",
       "      <td>0.007860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>max_stock_shift2</td>\n",
       "      <td>0.007766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ratio_min_stock_shift3</td>\n",
       "      <td>0.006921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>median_stock_shift3</td>\n",
       "      <td>0.006860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mean_stock_shift2</td>\n",
       "      <td>0.006415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>N8</td>\n",
       "      <td>0.006395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max_stock_shift1</td>\n",
       "      <td>0.005721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>median_stock_shift2</td>\n",
       "      <td>0.005272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mean_stock_shift3</td>\n",
       "      <td>0.005113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>median_stock_shift1</td>\n",
       "      <td>0.004863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>color_id</td>\n",
       "      <td>0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ratio_min_stock_shift2</td>\n",
       "      <td>0.003979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>max_stock_shift3</td>\n",
       "      <td>0.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ratio_median_stock_shift3</td>\n",
       "      <td>0.002670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ratio_min_stock_shift1</td>\n",
       "      <td>0.002418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ratio_mean_stock_shift2</td>\n",
       "      <td>0.002398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ratio_mean_stock_shift3</td>\n",
       "      <td>0.002245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ratio_median_stock_shift2</td>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ratio_max_stock_shift1</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ratio_mean_stock_shift1</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ratio_median_stock_shift1</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ratio_max_stock_shift3</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weekend</td>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ratio_max_stock_shift2</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kurtosis_stock_shift1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ratio_kurtosis_stock_shift1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  importance\n",
       "1                     std_stock    0.052005\n",
       "26             diff_stock_lead1    0.043378\n",
       "25        kurtosis_stock_shift2    0.038489\n",
       "27             diff_stock_lead2    0.036836\n",
       "0                         stock    0.033815\n",
       "29              diff_stock_lag2    0.032375\n",
       "55             ratio_std_shift2    0.032149\n",
       "54             ratio_std_shift1    0.030850\n",
       "35        kurtosis_stock_shift3    0.030336\n",
       "28              diff_stock_lag1    0.030156\n",
       "12             std_stock_shift1    0.028046\n",
       "20             std_stock_shift2    0.027685\n",
       "3                  subfamily_id    0.025130\n",
       "2                     family_id    0.023307\n",
       "63                           N9    0.022973\n",
       "66                          N12    0.022543\n",
       "7                         price    0.022541\n",
       "6                   category_id    0.021884\n",
       "18                   stock_lag2    0.020869\n",
       "19                  stock_lead2    0.020412\n",
       "10                   stock_lag1    0.019994\n",
       "58                           N3    0.019281\n",
       "56                           N1    0.018783\n",
       "60                           N6    0.018492\n",
       "11                  stock_lead1    0.018257\n",
       "64                          N10    0.017548\n",
       "32             min_stock_shift3    0.017470\n",
       "43  ratio_kurtosis_stock_shift2    0.015991\n",
       "67                          N13    0.015708\n",
       "59                           N5    0.015287\n",
       "..                          ...         ...\n",
       "37                 size_d_color    0.009318\n",
       "57                           N2    0.008444\n",
       "61                           N7    0.008340\n",
       "14             min_stock_shift1    0.008152\n",
       "13            mean_stock_shift1    0.007860\n",
       "22             max_stock_shift2    0.007766\n",
       "42       ratio_min_stock_shift3    0.006921\n",
       "34          median_stock_shift3    0.006860\n",
       "24            mean_stock_shift2    0.006415\n",
       "62                           N8    0.006395\n",
       "15             max_stock_shift1    0.005721\n",
       "23          median_stock_shift2    0.005272\n",
       "31            mean_stock_shift3    0.005113\n",
       "16          median_stock_shift1    0.004863\n",
       "5                      color_id    0.004066\n",
       "47       ratio_min_stock_shift2    0.003979\n",
       "33             max_stock_shift3    0.002906\n",
       "39    ratio_median_stock_shift3    0.002670\n",
       "52       ratio_min_stock_shift1    0.002418\n",
       "45      ratio_mean_stock_shift2    0.002398\n",
       "40      ratio_mean_stock_shift3    0.002245\n",
       "44    ratio_median_stock_shift2    0.001927\n",
       "51       ratio_max_stock_shift1    0.001747\n",
       "50      ratio_mean_stock_shift1    0.001686\n",
       "49    ratio_median_stock_shift1    0.001634\n",
       "41       ratio_max_stock_shift3    0.001335\n",
       "9                       weekend    0.001314\n",
       "46       ratio_max_stock_shift2    0.000553\n",
       "17        kurtosis_stock_shift1    0.000000\n",
       "48  ratio_kurtosis_stock_shift1    0.000000\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    xgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=100,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_metric='mae')\n",
    "\n",
    "    ft_importances += xgb_model.feature_importances_\n",
    "\n",
    "    be += np.expm1(xgb_model.best_score)\n",
    "    y_preds = np.expm1(xgb_model.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "pr = pd.DataFrame({'predicciones_xgboost': full_preds})\n",
    "pr.to_csv('../predictions/preds_xgboost.csv')\n",
    "\n",
    "print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "df_imp_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'depth':7,\n",
    "    'iterations':5000,\n",
    "    'eval_metric':'MAE',\n",
    "    'random_seed':42,\n",
    "    'early_stopping_rounds':[5],\n",
    "    'learning_rate':0.1,\n",
    "    'thread_count':8,\n",
    "    'boosting_type':'Plain',\n",
    "    'bootstrap_type':'Bernoulli',\n",
    "    'colsample_bylevel':0.6\n",
    "}\n",
    "\n",
    "model_cb = CatBoostRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ft = ['day']\n",
    "\n",
    "cat_ft_id = list()\n",
    "n = 0\n",
    "for c in X_train.columns:\n",
    "    if c in cat_ft:\n",
    "        cat_ft_id.append(n)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold k 1:\n",
      "0:\tlearn: 1.4991239\ttest: 1.5062907\tbest: 1.5062907 (0)\ttotal: 147ms\tremaining: 12m 16s\n",
      "200:\tlearn: 0.4450761\ttest: 0.4492521\tbest: 0.4492521 (200)\ttotal: 15.3s\tremaining: 6m 5s\n",
      "400:\tlearn: 0.4301489\ttest: 0.4377169\tbest: 0.4377169 (400)\ttotal: 30.3s\tremaining: 5m 47s\n",
      "600:\tlearn: 0.4212148\ttest: 0.4320753\tbest: 0.4320753 (600)\ttotal: 45.2s\tremaining: 5m 30s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-17e9e09e88a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                  \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_ft_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                  early_stopping_rounds=10)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mft_importances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel_cb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\u001b[0m\n\u001b[1;32m   2547\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m                          save_snapshot, snapshot_file, snapshot_interval)\n\u001b[0m\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_leaf_weights_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "ft_importances = np.zeros(X_train.shape[1])\n",
    "full_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('--- Fold k {}:'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    y_val = np.log1p(y_val)\n",
    "    y_fit = np.log1p(y_fit)\n",
    "\n",
    "    model_cb.fit(X_fit,\n",
    "                 y_fit,\n",
    "                 eval_set=[(X_val, y_val)],\n",
    "                 verbose=200,\n",
    "#                  cat_features=cat_ft_id,\n",
    "                 early_stopping_rounds=10)\n",
    "\n",
    "    ft_importances += model_cb.feature_importances_\n",
    "\n",
    "    be += np.expm1(model_cb.best_score_['validation_0']['MAE'])\n",
    "    y_preds = np.expm1(model_cb.predict(X_test))\n",
    "    full_preds += y_preds\n",
    "    y_preds = [int(round(x)) for x in y_preds]\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "full_preds = full_preds/k\n",
    "full_preds = [int(round(x)) for x in full_preds]\n",
    "\n",
    "pr = pd.DataFrame({'predicciones_catboost': full_preds})\n",
    "pr.to_csv('../predictions/preds_catboost.csv')\n",
    "\n",
    "print('IMPORTANCIA DE LAS VARIABLES:\\n')\n",
    "imp = pd.DataFrame({'feature': X_train.columns, 'importance': ft_importances/k})\n",
    "df_imp_sort = imp.sort_values('importance', ascending=False)\n",
    "df_imp_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = X_train.fillna(-1).sample(frac=0.1)\n",
    "X_fit, X_val, y_fit, y_val = train_test_split(X_train_sample,\n",
    "                                              y_train.iloc[X_train_sample.index.values],\n",
    "                                              test_size=0.25,\n",
    "                                              random_state=42)\n",
    "\n",
    "# y_val = np.log1p(y_val)\n",
    "# y_fit = np.log1p(y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=0.0,\n",
    "                           patience=3,\n",
    "                           verbose=0,\n",
    "                           mode='min',\n",
    "                           restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=baseline_model,\n",
    "                           epochs=100,\n",
    "                           batch_size=256,\n",
    "                           verbose=1,\n",
    "                           callbacks=callbacks,\n",
    "                           validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31354 samples, validate on 10452 samples\n",
      "Epoch 1/100\n",
      "31354/31354 [==============================] - 1s 21us/step - loss: 13.4573 - val_loss: 10.7097\n",
      "Epoch 2/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 10.6327 - val_loss: 10.2146\n",
      "Epoch 3/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 10.3378 - val_loss: 9.9781\n",
      "Epoch 4/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 10.1514 - val_loss: 9.8359\n",
      "Epoch 5/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 10.0166 - val_loss: 9.7235\n",
      "Epoch 6/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.8966 - val_loss: 9.6253\n",
      "Epoch 7/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.7960 - val_loss: 9.5547\n",
      "Epoch 8/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.6984 - val_loss: 9.4678\n",
      "Epoch 9/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.6101 - val_loss: 9.4206\n",
      "Epoch 10/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.5131 - val_loss: 9.3222\n",
      "Epoch 11/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.4250 - val_loss: 9.2346\n",
      "Epoch 12/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.3361 - val_loss: 9.1662\n",
      "Epoch 13/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.2589 - val_loss: 9.1236\n",
      "Epoch 14/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 9.2018 - val_loss: 9.0503\n",
      "Epoch 15/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 9.1310 - val_loss: 8.9930\n",
      "Epoch 16/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 9.0692 - val_loss: 8.9727\n",
      "Epoch 17/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 9.0190 - val_loss: 8.9125\n",
      "Epoch 18/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.9638 - val_loss: 8.9163\n",
      "Epoch 19/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.9095 - val_loss: 8.7977\n",
      "Epoch 20/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.8614 - val_loss: 8.7902\n",
      "Epoch 21/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.8255 - val_loss: 8.7320\n",
      "Epoch 22/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.7775 - val_loss: 8.6997\n",
      "Epoch 23/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.7382 - val_loss: 8.6620\n",
      "Epoch 24/100\n",
      "31354/31354 [==============================] - 0s 7us/step - loss: 8.7002 - val_loss: 8.6075\n",
      "Epoch 25/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.6607 - val_loss: 8.5902\n",
      "Epoch 26/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.6295 - val_loss: 8.6015\n",
      "Epoch 27/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.6038 - val_loss: 8.5334\n",
      "Epoch 28/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.5787 - val_loss: 8.5078\n",
      "Epoch 29/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.5399 - val_loss: 8.5107\n",
      "Epoch 30/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.5150 - val_loss: 8.4552\n",
      "Epoch 31/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.4939 - val_loss: 8.4317\n",
      "Epoch 32/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.4579 - val_loss: 8.4378\n",
      "Epoch 33/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.4357 - val_loss: 8.3869\n",
      "Epoch 34/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.4102 - val_loss: 8.3838\n",
      "Epoch 35/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.3936 - val_loss: 8.3593\n",
      "Epoch 36/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.3706 - val_loss: 8.3572\n",
      "Epoch 37/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.3505 - val_loss: 8.3018\n",
      "Epoch 38/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.3370 - val_loss: 8.3374\n",
      "Epoch 39/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.3154 - val_loss: 8.2826\n",
      "Epoch 40/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.2954 - val_loss: 8.3040\n",
      "Epoch 41/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.2883 - val_loss: 8.2610\n",
      "Epoch 42/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.2845 - val_loss: 8.2989\n",
      "Epoch 43/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.2773 - val_loss: 8.2383\n",
      "Epoch 44/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.2332 - val_loss: 8.2143\n",
      "Epoch 45/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.2208 - val_loss: 8.2096\n",
      "Epoch 46/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.2112 - val_loss: 8.1901\n",
      "Epoch 47/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.1963 - val_loss: 8.2161\n",
      "Epoch 48/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.1791 - val_loss: 8.1958\n",
      "Epoch 49/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.1721 - val_loss: 8.1619\n",
      "Epoch 50/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.1719 - val_loss: 8.1500\n",
      "Epoch 51/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.1406 - val_loss: 8.2160\n",
      "Epoch 52/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.1338 - val_loss: 8.1411\n",
      "Epoch 53/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.1447 - val_loss: 8.1409\n",
      "Epoch 54/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.1134 - val_loss: 8.1600\n",
      "Epoch 55/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.0961 - val_loss: 8.1171\n",
      "Epoch 56/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.0959 - val_loss: 8.1427\n",
      "Epoch 57/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.0879 - val_loss: 8.1216\n",
      "Epoch 58/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.0809 - val_loss: 8.0934\n",
      "Epoch 59/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.0497 - val_loss: 8.0977\n",
      "Epoch 60/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.0680 - val_loss: 8.0839\n",
      "Epoch 61/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.0315 - val_loss: 8.0724\n",
      "Epoch 62/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.0258 - val_loss: 8.0838\n",
      "Epoch 63/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 8.0262 - val_loss: 8.0680\n",
      "Epoch 64/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 8.0108 - val_loss: 8.0579\n",
      "Epoch 65/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 7.9978 - val_loss: 8.1124\n",
      "Epoch 66/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 7.9956 - val_loss: 8.0593\n",
      "Epoch 67/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 7.9797 - val_loss: 8.0520\n",
      "Epoch 68/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 7.9747 - val_loss: 8.0392\n",
      "Epoch 69/100\n",
      "31354/31354 [==============================] - 0s 6us/step - loss: 7.9596 - val_loss: 8.0393\n",
      "Epoch 70/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 7.9661 - val_loss: 8.0246\n",
      "Epoch 71/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 7.9331 - val_loss: 8.0134\n",
      "Epoch 72/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 7.9366 - val_loss: 8.0202\n",
      "Epoch 73/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 7.9224 - val_loss: 8.0139\n",
      "Epoch 74/100\n",
      "31354/31354 [==============================] - 0s 5us/step - loss: 7.9131 - val_loss: 8.0327\n"
     ]
    }
   ],
   "source": [
    "history = estimator.fit(X_fit, y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62244/62244 [==============================] - 0s 2us/step\n"
     ]
    }
   ],
   "source": [
    "keras_preds = estimator.predict(X_test.fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.107843  ,   6.584964  ,  22.428284  ,  11.540891  ,\n",
       "        10.668456  ,  15.1289425 ,  18.780174  ,  -0.15252957,\n",
       "        18.802126  ,  24.512297  ,   7.9419694 ,  38.281567  ,\n",
       "         1.6043679 ,   2.1568155 , 102.12486   ,  41.492683  ,\n",
       "       110.67814   ,   4.0001807 ,  15.984176  ,  19.690142  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(keras_preds)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train.index\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold k 1\n",
      "\n",
      "Score en el test: 11.170156919880345 ventas\n",
      "Fold k 2\n",
      "\n",
      "Score en el test: 11.252111454322224 ventas\n",
      "Fold k 3\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a705e8a0ff9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     y_fit = np.log1p(y_fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score en el test:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ventas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    760\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                           check_input=False)\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    476\u001b[0m             model = cd_fast.enet_coordinate_descent(\n\u001b[1;32m    477\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 positive)\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             raise ValueError(\"Precompute should be one of True, False, \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    print('Fold k {}\\n'.format(counter))\n",
    "\n",
    "    X_fit, X_val = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "    y_fit, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    X_fit = X_fit.fillna(-1)\n",
    "    X_val = X_val.fillna(-1)\n",
    "    \n",
    "#     y_val = np.log1p(y_val)\n",
    "#     y_fit = np.log1p(y_fit)\n",
    "    \n",
    "    lasso.fit(X_fit, y_fit)\n",
    "    \n",
    "    print('Score en el test:',mean_absolute_error(lasso.predict(X_test.fillna(-1)), y_test),'ventas')\n",
    "#     print('Score en el test:',mean_absolute_error(np.expm1(lasso.predict(X_test.fillna(-1))), y_test),'ventas')\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    \n",
    "# print('\\n\\nBEST SCORE MEAN:', be / k,'SALES :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid_0's l1: 14.9035\n",
      "[2000]\tvalid_0's l1: 14.148\n",
      "[3000]\tvalid_0's l1: 13.7446\n",
      "Early stopping, best iteration is:\n",
      "[3494]\tvalid_0's l1: 13.6114\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid_0's l1: 12.3938\n",
      "[2000]\tvalid_0's l1: 11.7195\n",
      "[3000]\tvalid_0's l1: 11.3735\n",
      "Early stopping, best iteration is:\n",
      "[3420]\tvalid_0's l1: 11.2791\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid_0's l1: 10.2273\n",
      "Early stopping, best iteration is:\n",
      "[1032]\tvalid_0's l1: 10.1833\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[823]\tvalid_0's l1: 9.79996\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid_0's l1: 8.96911\n",
      "Early stopping, best iteration is:\n",
      "[1033]\tvalid_0's l1: 8.93757\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "be = 0\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_fit, X_val = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_fit, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     y_val = np.log1p(y_val)\n",
    "#     y_fit = np.log1p(y_fit)\n",
    "    \n",
    "    \n",
    "    lgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=1000,\n",
    "                  early_stopping_rounds=20)\n",
    "\n",
    "\n",
    "#     be += np.expm1(lgb_model.best_score_['valid_0']['l1'])\n",
    "    be += lgb_model.best_score_['valid_0']['l1']\n",
    "    \n",
    "#     print('Score en el test:',mean_absolute_error(lgb_model.predict(X_test), y_test),'ventas')\n",
    "#     print('Score en el test:',mean_absolute_error(np.expm1(lgb_model.predict(X_test)), y_test),'ventas')\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
